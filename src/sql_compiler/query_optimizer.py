# -*- coding: utf-8 -*-
"""
æŸ¥è¯¢ä¼˜åŒ–å™¨ - AODSQLç³»ç»Ÿçš„æ ¸å¿ƒä¼˜åŒ–ç»„ä»¶
å®ç°åŸºäºæˆæœ¬çš„ä¼˜åŒ–(CBO)å’ŒåŸºäºè§„åˆ™çš„ä¼˜åŒ–(RBO)
"""

from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import math
import time
import threading
import concurrent.futures
from concurrent.futures import ThreadPoolExecutor
from .logical_operators import LogicalOperator, LogicalPlan
from .logical_operators import ScanOperator, FilterOperator, IndexScanOperator, JoinOperator
from .symbol_table import SymbolTable, TableInfo
from src.engine.catalog_manager import CatalogManager
from .enhanced_query_planner import EnhancedQueryPlanner

class OptimizationStrategy(Enum):
    """ä¼˜åŒ–ç­–ç•¥æšä¸¾"""
    RULE_BASED = "rule_based"      # åŸºäºè§„åˆ™çš„ä¼˜åŒ–
    COST_BASED = "cost_based"      # åŸºäºæˆæœ¬çš„ä¼˜åŒ–
    HYBRID = "hybrid"              # æ··åˆä¼˜åŒ–ç­–ç•¥

class JoinMethod(Enum):
    """è¿æ¥æ–¹æ³•æšä¸¾"""
    NESTED_LOOP = "nested_loop"    # åµŒå¥—å¾ªç¯è¿æ¥
    HASH_JOIN = "hash_join"        # å“ˆå¸Œè¿æ¥
    SORT_MERGE = "sort_merge"      # æ’åºåˆå¹¶è¿æ¥


class ParallelStrategy(Enum):
    """å¹¶è¡Œç­–ç•¥æšä¸¾"""
    SEQUENTIAL = "sequential"      # é¡ºåºæ‰§è¡Œ
    PARALLEL_SCAN = "parallel_scan" # å¹¶è¡Œæ‰«æ
    PARALLEL_JOIN = "parallel_join" # å¹¶è¡Œè¿æ¥
    PARALLEL_OPTIMIZATION = "parallel_optimization" # å¹¶è¡Œä¼˜åŒ–

@dataclass
class CostInfo:
    """æˆæœ¬ä¿¡æ¯"""
    io_cost: float = 0.0          # I/Oæˆæœ¬
    cpu_cost: float = 0.0         # CPUæˆæœ¬
    memory_cost: float = 0.0      # å†…å­˜æˆæœ¬
    total_cost: float = 0.0       # æ€»æˆæœ¬
    
    def __post_init__(self):
        # å¢åŠ ç´¢å¼•ä¼˜åŒ–æƒé‡ç³»æ•°
        self.total_cost = self.io_cost * 0.7 + self.cpu_cost * 0.25 + self.memory_cost * 0.05

@dataclass
class Statistics:
    """ç»Ÿè®¡ä¿¡æ¯"""
    table_name: str
    row_count: int = 0
    page_count: int = 0
    avg_row_size: float = 0.0
    column_stats: Dict[str, 'ColumnStatistics'] = None
    
    def __post_init__(self):
        if self.column_stats is None:
            self.column_stats = {}

@dataclass
class ColumnStatistics:
    """åˆ—ç»Ÿè®¡ä¿¡æ¯"""
    column_name: str
    distinct_count: int = 0
    null_count: int = 0
    min_value: Any = None
    max_value: Any = None
    most_common_values: List[Tuple[Any, int]] = None
    histogram: List[Tuple[Any, int]] = None  # ç›´æ–¹å›¾ç»Ÿè®¡
    correlation_with_other_columns: Dict[str, float] = None  # ä¸å…¶ä»–åˆ—çš„ç›¸å…³æ€§
    
    def __post_init__(self):
        if self.most_common_values is None:
            self.most_common_values = []
        if self.histogram is None:
            self.histogram = []
        if self.correlation_with_other_columns is None:
            self.correlation_with_other_columns = {}

@dataclass
class EnhancedStatistics:
    """å¢å¼ºçš„ç»Ÿè®¡ä¿¡æ¯"""
    table_name: str
    row_count: int = 0
    page_count: int = 0
    avg_row_size: float = 0.0
    column_stats: Dict[str, ColumnStatistics] = None
    last_updated: float = 0.0  # æœ€åæ›´æ–°æ—¶é—´æˆ³
    update_frequency: int = 1000  # æ›´æ–°é¢‘ç‡ï¼ˆæ¯1000æ¬¡æ“ä½œæ›´æ–°ä¸€æ¬¡ï¼‰
    operation_count: int = 0  # æ“ä½œè®¡æ•°å™¨
    
    def __post_init__(self):
        if self.column_stats is None:
            self.column_stats = {}
        if self.last_updated == 0.0:
            self.last_updated = time.time()

@dataclass
class ParallelExecutionInfo:
    """å¹¶è¡Œæ‰§è¡Œä¿¡æ¯"""
    strategy: ParallelStrategy = ParallelStrategy.SEQUENTIAL
    max_workers: int = 4
    estimated_parallelism: float = 1.0
    parallel_cost_reduction: float = 0.0
    
@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœ"""
    plan: LogicalPlan
    cost: CostInfo
    parallel_info: Optional[ParallelExecutionInfo] = None
    optimization_time: float = 0.0

@dataclass
class AdaptiveParameters:
    """è‡ªé€‚åº”å‚æ•°"""
    io_cost_per_page: float = 1.0
    cpu_cost_per_row: float = 0.001
    memory_cost_per_page: float = 0.1
    index_seek_cost_per_level: float = 0.1
    index_scan_cost_per_row: float = 0.01
    index_fetch_cost_per_page: float = 0.1
    index_cpu_cost_per_row: float = 0.0001
    index_memory_cost: float = 0.05
    
    # è‡ªé€‚åº”è°ƒæ•´å› å­
    io_adjustment_factor: float = 1.0
    cpu_adjustment_factor: float = 1.0
    memory_adjustment_factor: float = 1.0
    
    def apply_adjustments(self):
        """åº”ç”¨è°ƒæ•´å› å­"""
        self.io_cost_per_page *= self.io_adjustment_factor
        self.cpu_cost_per_row *= self.cpu_adjustment_factor
        self.memory_cost_per_page *= self.memory_adjustment_factor
        self.index_seek_cost_per_level *= self.cpu_adjustment_factor
        self.index_scan_cost_per_row *= self.cpu_adjustment_factor
        self.index_fetch_cost_per_page *= self.io_adjustment_factor
        self.index_cpu_cost_per_row *= self.cpu_adjustment_factor
        self.index_memory_cost *= self.memory_adjustment_factor

class StatisticsCollector:
    """ç»Ÿè®¡ä¿¡æ¯æ”¶é›†å™¨"""
    
    def __init__(self, catalog_manager: CatalogManager = None):
        self.catalog = catalog_manager
        self.collection_cache = {}  # æ”¶é›†ç¼“å­˜
        self.collection_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
    
    def collect_table_statistics(self, table_name: str, force_refresh: bool = False) -> EnhancedStatistics:
        """æ”¶é›†è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        with self.collection_lock:
            # æ£€æŸ¥ç¼“å­˜
            if not force_refresh and table_name in self.collection_cache:
                cached_stats = self.collection_cache[table_name]
                if time.time() - cached_stats.last_updated < 3600:  # 1å°æ—¶å†…ä¸é‡æ–°æ”¶é›†
                    return cached_stats
            
            # ä»catalogè·å–åŸºç¡€ä¿¡æ¯
            table_info = self.catalog.get_table(table_name) if self.catalog else None
            
            # åˆ›å»ºå¢å¼ºç»Ÿè®¡ä¿¡æ¯
            stats = EnhancedStatistics(
                table_name=table_name,
                row_count=getattr(table_info, 'row_count', 0) if table_info else 0,
                page_count=getattr(table_info, 'page_count', 0) if table_info else 0,
                avg_row_size=self._estimate_avg_row_size(table_info) if table_info else 0.0,
                last_updated=time.time()
            )
            
            # æ”¶é›†åˆ—ç»Ÿè®¡ä¿¡æ¯
            if table_info and hasattr(table_info, 'columns'):
                for column in table_info.columns:
                    col_stats = self._collect_column_statistics(table_name, column.column_name)
                    stats.column_stats[column.column_name] = col_stats
            
            # æ›´æ–°ç¼“å­˜
            self.collection_cache[table_name] = stats
            return stats
    
    def _collect_column_statistics(self, table_name: str, column_name: str) -> ColumnStatistics:
        """æ”¶é›†åˆ—ç»Ÿè®¡ä¿¡æ¯"""
        col_stats = ColumnStatistics(column_name=column_name)
        
        if self.catalog:
            try:
                # ä»catalogè·å–åˆ—ç»Ÿè®¡ä¿¡æ¯
                catalog_col_stats = self.catalog.get_column_stats(table_name, column_name)
                if catalog_col_stats:
                    col_stats.distinct_count = catalog_col_stats.get('distinct', 0)
                    col_stats.null_count = catalog_col_stats.get('null_count', 0)
                    col_stats.min_value = catalog_col_stats.get('min')
                    col_stats.max_value = catalog_col_stats.get('max')
                    col_stats.most_common_values = catalog_col_stats.get('mcv', [])
                    col_stats.histogram = catalog_col_stats.get('histogram', [])
            except Exception as e:
                # å¦‚æœè·å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                pass
        
        return col_stats
    
    def _estimate_avg_row_size(self, table_info) -> float:
        """ä¼°ç®—å¹³å‡è¡Œå¤§å°"""
        if not table_info or not hasattr(table_info, 'columns'):
            return 100.0  # é»˜è®¤è¡Œå¤§å°
        
        total_size = 0
        for column in table_info.columns:
            if hasattr(column, 'data_type'):
                if column.data_type == 'INT':
                    total_size += 4
                elif column.data_type == 'VARCHAR':
                    total_size += 50  # å‡è®¾å¹³å‡50å­—ç¬¦
                elif column.data_type == 'DECIMAL':
                    total_size += 8
                else:
                    total_size += 4
        
        return float(total_size)
    
    def update_statistics_after_operation(self, table_name: str, operation_type: str, affected_rows: int = 0):
        """åœ¨æ“ä½œåæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        with self.collection_lock:
            if table_name in self.collection_cache:
                stats = self.collection_cache[table_name]
                stats.operation_count += 1
                
                # æ ¹æ®æ“ä½œç±»å‹æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
                if operation_type == 'INSERT':
                    stats.row_count += affected_rows
                elif operation_type == 'DELETE':
                    stats.row_count = max(0, stats.row_count - affected_rows)
                elif operation_type == 'UPDATE':
                    # UPDATEä¸æ”¹å˜è¡Œæ•°ï¼Œä½†å¯èƒ½éœ€è¦æ›´æ–°åˆ—ç»Ÿè®¡ä¿¡æ¯
                    pass
                
                # æ£€æŸ¥æ˜¯å¦éœ€è¦é‡æ–°æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
                if stats.operation_count >= stats.update_frequency:
                    self.collect_table_statistics(table_name, force_refresh=True)
    
    def get_statistics_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯æ‘˜è¦"""
        with self.collection_lock:
            summary = {
                'cached_tables': len(self.collection_cache),
                'tables': {}
            }
            
            for table_name, stats in self.collection_cache.items():
                summary['tables'][table_name] = {
                    'row_count': stats.row_count,
                    'page_count': stats.page_count,
                    'avg_row_size': stats.avg_row_size,
                    'last_updated': stats.last_updated,
                    'operation_count': stats.operation_count,
                    'columns_count': len(stats.column_stats)
                }
            
            return summary

class QueryOptimizer:
    """æŸ¥è¯¢ä¼˜åŒ–å™¨"""
    
    def __init__(self, symbol_table: SymbolTable, strategy: OptimizationStrategy = OptimizationStrategy.HYBRID, catalog_manager: CatalogManager = None, enable_optimization: bool = True, enable_parallel: bool = True):
        self.symbol_table = symbol_table
        self.strategy = strategy
        self.statistics = {}  # è¡¨ç»Ÿè®¡ä¿¡æ¯
        self.catalog = catalog_manager
        self.card_estimator = CardinalityEstimator(catalog_manager)
        
        # æ¼”ç¤ºæ¨¡å¼å¼€å…³
        self.enable_optimization = enable_optimization
        self.enable_parallel = enable_parallel
        self.demo_mode = False  # æ¼”ç¤ºæ¨¡å¼æ ‡å¿—
        
        # å¹¶è¡Œæ‰§è¡Œé…ç½®
        self.max_workers = 4
        self.parallel_threshold = 1000  # è¶…è¿‡1000è¡Œçš„è¡¨æ‰è€ƒè™‘å¹¶è¡Œ
        
        # è‡ªé€‚åº”å‚æ•°è°ƒä¼˜
        self.adaptive_params = AdaptiveParameters()
        self.enable_adaptive_tuning = True
        self.performance_history = []  # å­˜å‚¨æ€§èƒ½å†å²ç”¨äºè‡ªé€‚åº”è°ƒä¼˜
        
        # å¢å¼ºç»Ÿè®¡ä¿¡æ¯æ”¶é›†
        self.statistics_collector = StatisticsCollector(catalog_manager)
        self.enable_enhanced_statistics = True
        
        # åˆå§‹åŒ–æˆæœ¬æ¨¡å‹å’Œè§„åˆ™å¼•æ“ï¼ˆåœ¨è‡ªé€‚åº”å‚æ•°ä¹‹åï¼‰
        self.cost_model = CostModel(catalog_manager, self.adaptive_params)  # ä¼ é€’catalogå’Œè‡ªé€‚åº”å‚æ•°ç»™æˆæœ¬æ¨¡å‹
        self.rule_engine = RuleEngine(catalog_manager, statistics_supplier=lambda: self.statistics)
        
        # åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯
        self._initialize_statistics()
    
    def optimize(self, logical_plan: LogicalPlan) -> LogicalPlan:
        """
        ä¼˜åŒ–é€»è¾‘æ‰§è¡Œè®¡åˆ’
        è¾“å…¥: åŸå§‹é€»è¾‘è®¡åˆ’
        è¾“å‡º: ä¼˜åŒ–åçš„é€»è¾‘è®¡åˆ’
        """
        start_time = time.time()
        
        # å¦‚æœç¦ç”¨ä¼˜åŒ–ï¼Œç›´æ¥è¿”å›åŸå§‹è®¡åˆ’
        if not self.enable_optimization:
            return logical_plan
            
        # åªåœ¨æ¼”ç¤ºæ¨¡å¼ä¸‹æ‰“å°è¯¦ç»†ä¿¡æ¯
        if self.demo_mode:
            print(f"ğŸ”§ å¼€å§‹æŸ¥è¯¢ä¼˜åŒ– (ç­–ç•¥: {self.strategy.value})")
        
        # 1. æŸ¥è¯¢é‡å†™
        rewritten_plan = self._rewrite_query(logical_plan)
        if self.demo_mode:
            print("   âœ… æŸ¥è¯¢é‡å†™å®Œæˆ")
        
        # 2. åŸºäºè§„åˆ™çš„ä¼˜åŒ–
        if self.strategy in [OptimizationStrategy.RULE_BASED, OptimizationStrategy.HYBRID]:
            rule_optimized_plan = self._rule_based_optimization(rewritten_plan)
            if self.demo_mode:
                print("   âœ… åŸºäºè§„åˆ™çš„ä¼˜åŒ–å®Œæˆ")
        else:
            rule_optimized_plan = rewritten_plan
        
        # 3. åŸºäºæˆæœ¬çš„ä¼˜åŒ–ï¼ˆæ”¯æŒå¹¶è¡Œï¼‰
        if self.strategy in [OptimizationStrategy.COST_BASED, OptimizationStrategy.HYBRID]:
            if self.enable_parallel:
                cost_optimized_plan = self._parallel_cost_based_optimization(rule_optimized_plan)
            else:
                cost_optimized_plan = self._cost_based_optimization(rule_optimized_plan)
            if self.demo_mode:
                print("   âœ… åŸºäºæˆæœ¬çš„ä¼˜åŒ–å®Œæˆ")
        else:
            cost_optimized_plan = rule_optimized_plan
        
        # 4. ä¸ºä¼˜åŒ–åçš„è®¡åˆ’æ·»åŠ æˆæœ¬ä¼°ç®—ä¿¡æ¯
        self._add_cost_estimates(cost_optimized_plan)
        
        # 5. ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Šï¼ˆä»…åœ¨æ¼”ç¤ºæ¨¡å¼ï¼‰
        if self.demo_mode:
            optimization_time = time.time() - start_time
            self._generate_optimization_report(logical_plan, cost_optimized_plan, optimization_time)
            self._show_optimization_decisions()
        
        return cost_optimized_plan
    
    def _add_cost_estimates(self, plan: LogicalPlan):
        """ä¸ºé€»è¾‘è®¡åˆ’æ·»åŠ æˆæœ¬ä¼°ç®—ä¿¡æ¯"""
        if not plan or not plan.root:
            return
        
        # è®¡ç®—æ¯ä¸ªæ“ä½œç¬¦çš„æˆæœ¬å’Œè¡Œæ•°ä¼°ç®—
        self._calculate_operator_costs(plan.root)
    
    def _calculate_operator_costs(self, operator: LogicalOperator):
        """é€’å½’è®¡ç®—æ“ä½œç¬¦çš„æˆæœ¬å’Œè¡Œæ•°ä¼°ç®—"""
        if not operator:
            return
        
        # è®¡ç®—å½“å‰æ“ä½œç¬¦çš„æˆæœ¬
        cost_info = self.cost_model.calculate_cost(LogicalPlan(operator), self.statistics)
        
        # è®¾ç½®ä¼°ç®—ä¿¡æ¯
        operator.estimated_cost = cost_info.total_cost
        operator.estimated_rows = self._estimate_operator_rows(operator)
        
        # é€’å½’å¤„ç†å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                self._calculate_operator_costs(child)
        elif hasattr(operator, 'left_child') and operator.left_child:
            self._calculate_operator_costs(operator.left_child)
        if hasattr(operator, 'right_child') and operator.right_child:
            self._calculate_operator_costs(operator.right_child)
    
    def _estimate_operator_rows(self, operator: LogicalOperator) -> int:
        """ä¼°ç®—æ“ä½œç¬¦çš„è¾“å‡ºè¡Œæ•°"""
        if hasattr(operator, 'table_name'):
            # æ‰«ææ“ä½œç¬¦
            table_name = operator.table_name
            if table_name in self.statistics:
                return self.statistics[table_name].row_count
            return 1000  # é»˜è®¤ä¼°ç®—
        
        if hasattr(operator, 'operator_type'):
            op_type = operator.operator_type.value
            if op_type == 'Filter':
                # è¿‡æ»¤æ“ä½œç¬¦ï¼Œå‡è®¾é€‰æ‹©æ€§ä¸º0.1
                if hasattr(operator, 'children') and operator.children:
                    child_rows = self._estimate_operator_rows(operator.children[0])
                    return max(1, int(child_rows * 0.1))
            elif op_type == 'Project':
                # æŠ•å½±æ“ä½œç¬¦ï¼Œè¡Œæ•°ä¸å˜
                if hasattr(operator, 'children') and operator.children:
                    return self._estimate_operator_rows(operator.children[0])
        
        return 1000  # é»˜è®¤ä¼°ç®—
    
    def _show_optimization_decisions(self):
        """æ˜¾ç¤ºä¼˜åŒ–å†³ç­–è¿‡ç¨‹"""
        print("\nğŸ” ä¼˜åŒ–å†³ç­–è¯¦æƒ…:")
        print("   " + "="*50)
        
        decisions = self.rule_engine.get_decisions()
        if decisions:
            for i, decision in enumerate(decisions, 1):
                print(f"   å†³ç­– {i}:")
                print(f"     è¡¨: {decision.get('table', 'N/A')}")
                print(f"     åˆ—: {decision.get('column', 'N/A')}")
                print(f"     è°“è¯: {decision.get('predicate', 'N/A')}")
                print(f"     æ“ä½œç¬¦: {decision.get('operator', 'N/A')}")
                print(f"     é€‰æ‹©æ€§: {decision.get('selectivity_estimate', 0):.4f}")
                print(f"     å…¨è¡¨æ‰«ææˆæœ¬: {decision.get('seq_cost_estimate', 0):.2f}")
                print(f"     ç´¢å¼•æ‰«ææˆæœ¬: {decision.get('index_cost_estimate', 0):.2f}")
                print(f"     é€‰æ‹©: {decision.get('chosen', 'N/A')}")
                print(f"     ç´¢å¼•å: {decision.get('index_name', 'N/A')}")
                print()
        else:
            print("   æ²¡æœ‰æ‰¾åˆ°ç´¢å¼•é€‰æ‹©å†³ç­–")
        
        print("   " + "="*50)
    
    def _rewrite_query(self, plan: LogicalPlan) -> LogicalPlan:
        """æŸ¥è¯¢é‡å†™"""
        # 1. æ¶ˆé™¤å†—ä½™å­æŸ¥è¯¢
        # 2. ç®€åŒ–è¡¨è¾¾å¼
        # 3. è°“è¯ä¸‹æ¨
        # 4. åˆ—è£å‰ª
        return plan
    
    def _rule_based_optimization(self, plan: LogicalPlan) -> LogicalPlan:
        """åŸºäºè§„åˆ™çš„ä¼˜åŒ–"""
        return self.rule_engine.optimize(plan)
    
    def _cost_based_optimization(self, plan: LogicalPlan) -> LogicalPlan:
        """åŸºäºæˆæœ¬çš„ä¼˜åŒ–"""
        # 1. ç”Ÿæˆå€™é€‰æ‰§è¡Œè®¡åˆ’
        candidate_plans = self._generate_candidate_plans(plan)
        
        # 2. è®¡ç®—æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬
        best_plan = None
        best_cost = float('inf')
        
        for candidate_plan in candidate_plans:
            cost = self.cost_model.calculate_cost(candidate_plan, self.statistics)
            if self.demo_mode:
                print(f"   ğŸ“Š å€™é€‰è®¡åˆ’æˆæœ¬: {cost.total_cost:.2f}")
            
            if cost.total_cost < best_cost:
                best_cost = cost.total_cost
                best_plan = candidate_plan
        
        if self.demo_mode:
            print(f"   ğŸ† æœ€ä¼˜è®¡åˆ’æˆæœ¬: {best_cost:.2f}")
        return best_plan or plan
    
    def _parallel_cost_based_optimization(self, plan: LogicalPlan) -> LogicalPlan:
        """å¹¶è¡ŒåŸºäºæˆæœ¬çš„ä¼˜åŒ–"""
        if self.demo_mode:
            print("   ğŸš€ å¯ç”¨å¹¶è¡Œä¼˜åŒ–")
        
        # 1. ç”Ÿæˆå€™é€‰æ‰§è¡Œè®¡åˆ’
        candidate_plans = self._generate_candidate_plans(plan)
        
        # 2. å¹¶è¡Œè®¡ç®—æ¯ä¸ªè®¡åˆ’çš„æˆæœ¬
        best_plan = None
        best_cost = float('inf')
        
        if len(candidate_plans) > 1 and self.enable_parallel:
            # ä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œè®¡ç®—æˆæœ¬
            with ThreadPoolExecutor(max_workers=min(self.max_workers, len(candidate_plans))) as executor:
                # æäº¤æ‰€æœ‰æˆæœ¬è®¡ç®—ä»»åŠ¡
                future_to_plan = {
                    executor.submit(self.cost_model.calculate_cost, candidate_plan, self.statistics): candidate_plan
                    for candidate_plan in candidate_plans
                }
                
                # æ”¶é›†ç»“æœ
                for future in concurrent.futures.as_completed(future_to_plan):
                    candidate_plan = future_to_plan[future]
                    try:
                        cost = future.result()
                        if self.demo_mode:
                            print(f"   ğŸ“Š å€™é€‰è®¡åˆ’æˆæœ¬: {cost.total_cost:.2f}")
                        
                        if cost.total_cost < best_cost:
                            best_cost = cost.total_cost
                            best_plan = candidate_plan
                    except Exception as e:
                        if self.demo_mode:
                            print(f"   âš ï¸ æˆæœ¬è®¡ç®—å¤±è´¥: {e}")
        else:
            # é¡ºåºè®¡ç®—æˆæœ¬
            for candidate_plan in candidate_plans:
                cost = self.cost_model.calculate_cost(candidate_plan, self.statistics)
                if self.demo_mode:
                    print(f"   ğŸ“Š å€™é€‰è®¡åˆ’æˆæœ¬: {cost.total_cost:.2f}")
                
                if cost.total_cost < best_cost:
                    best_cost = cost.total_cost
                    best_plan = candidate_plan
        
        if self.demo_mode:
            print(f"   ğŸ† æœ€ä¼˜è®¡åˆ’æˆæœ¬: {best_cost:.2f}")
        
        return best_plan or plan
    
    def adaptive_tune_parameters(self, actual_performance: Dict[str, float]):
        """è‡ªé€‚åº”è°ƒä¼˜å‚æ•°"""
        if not self.enable_adaptive_tuning:
            return
        
        # è®°å½•æ€§èƒ½å†å²
        self.performance_history.append({
            'timestamp': time.time(),
            'performance': actual_performance,
            'params': {
                'io_cost_per_page': self.adaptive_params.io_cost_per_page,
                'cpu_cost_per_row': self.adaptive_params.cpu_cost_per_row,
                'memory_cost_per_page': self.adaptive_params.memory_cost_per_page
            }
        })
        
        # ä¿æŒæœ€è¿‘100æ¡è®°å½•
        if len(self.performance_history) > 100:
            self.performance_history = self.performance_history[-100:]
        
        # åˆ†ææ€§èƒ½è¶‹åŠ¿å¹¶è°ƒæ•´å‚æ•°
        if len(self.performance_history) >= 10:
            self._analyze_and_adjust_parameters()
    
    def _analyze_and_adjust_parameters(self):
        """åˆ†ææ€§èƒ½è¶‹åŠ¿å¹¶è°ƒæ•´å‚æ•°"""
        recent_performance = self.performance_history[-10:]
        
        # è®¡ç®—å¹³å‡æ€§èƒ½æŒ‡æ ‡
        avg_io_time = sum(p['performance'].get('io_time', 0) for p in recent_performance) / len(recent_performance)
        avg_cpu_time = sum(p['performance'].get('cpu_time', 0) for p in recent_performance) / len(recent_performance)
        avg_memory_usage = sum(p['performance'].get('memory_usage', 0) for p in recent_performance) / len(recent_performance)
        
        # ä¸å†å²å¹³å‡å€¼æ¯”è¾ƒ
        if len(self.performance_history) >= 20:
            historical_avg_io = sum(p['performance'].get('io_time', 0) for p in self.performance_history[-20:-10]) / 10
            historical_avg_cpu = sum(p['performance'].get('cpu_time', 0) for p in self.performance_history[-20:-10]) / 10
            historical_avg_memory = sum(p['performance'].get('memory_usage', 0) for p in self.performance_history[-20:-10]) / 10
            
            # è°ƒæ•´I/Oæˆæœ¬å‚æ•°
            if avg_io_time > historical_avg_io * 1.1:  # I/Oæ—¶é—´å¢åŠ è¶…è¿‡10%
                self.adaptive_params.io_adjustment_factor *= 1.05  # å¢åŠ I/Oæˆæœ¬æƒé‡
            elif avg_io_time < historical_avg_io * 0.9:  # I/Oæ—¶é—´å‡å°‘è¶…è¿‡10%
                self.adaptive_params.io_adjustment_factor *= 0.95  # å‡å°‘I/Oæˆæœ¬æƒé‡
            
            # è°ƒæ•´CPUæˆæœ¬å‚æ•°
            if avg_cpu_time > historical_avg_cpu * 1.1:  # CPUæ—¶é—´å¢åŠ è¶…è¿‡10%
                self.adaptive_params.cpu_adjustment_factor *= 1.05  # å¢åŠ CPUæˆæœ¬æƒé‡
            elif avg_cpu_time < historical_avg_cpu * 0.9:  # CPUæ—¶é—´å‡å°‘è¶…è¿‡10%
                self.adaptive_params.cpu_adjustment_factor *= 0.95  # å‡å°‘CPUæˆæœ¬æƒé‡
            
            # è°ƒæ•´å†…å­˜æˆæœ¬å‚æ•°
            if avg_memory_usage > historical_avg_memory * 1.1:  # å†…å­˜ä½¿ç”¨å¢åŠ è¶…è¿‡10%
                self.adaptive_params.memory_adjustment_factor *= 1.05  # å¢åŠ å†…å­˜æˆæœ¬æƒé‡
            elif avg_memory_usage < historical_avg_memory * 0.9:  # å†…å­˜ä½¿ç”¨å‡å°‘è¶…è¿‡10%
                self.adaptive_params.memory_adjustment_factor *= 0.95  # å‡å°‘å†…å­˜æˆæœ¬æƒé‡
            
            # åº”ç”¨è°ƒæ•´
            self.adaptive_params.apply_adjustments()
            
            # æ›´æ–°æˆæœ¬æ¨¡å‹
            self.cost_model._apply_adaptive_parameters()
            
            if self.demo_mode:
                print(f"   ğŸ”§ è‡ªé€‚åº”å‚æ•°è°ƒä¼˜:")
                print(f"     I/Oè°ƒæ•´å› å­: {self.adaptive_params.io_adjustment_factor:.3f}")
                print(f"     CPUè°ƒæ•´å› å­: {self.adaptive_params.cpu_adjustment_factor:.3f}")
                print(f"     å†…å­˜è°ƒæ•´å› å­: {self.adaptive_params.memory_adjustment_factor:.3f}")
    
    def get_adaptive_parameters_info(self) -> Dict[str, Any]:
        """è·å–è‡ªé€‚åº”å‚æ•°ä¿¡æ¯"""
        return {
            'io_cost_per_page': self.adaptive_params.io_cost_per_page,
            'cpu_cost_per_row': self.adaptive_params.cpu_cost_per_row,
            'memory_cost_per_page': self.adaptive_params.memory_cost_per_page,
            'io_adjustment_factor': self.adaptive_params.io_adjustment_factor,
            'cpu_adjustment_factor': self.adaptive_params.cpu_adjustment_factor,
            'memory_adjustment_factor': self.adaptive_params.memory_adjustment_factor,
            'performance_history_size': len(self.performance_history)
        }
    
    def update_statistics_after_operation(self, table_name: str, operation_type: str, affected_rows: int = 0):
        """åœ¨æ“ä½œåæ›´æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if self.enable_enhanced_statistics:
            self.statistics_collector.update_statistics_after_operation(table_name, operation_type, affected_rows)
            
            # é‡æ–°æ”¶é›†ç»Ÿè®¡ä¿¡æ¯
            enhanced_stats = self.statistics_collector.collect_table_statistics(table_name)
            
            # æ›´æ–°å†…éƒ¨ç»Ÿè®¡ä¿¡æ¯
            if table_name in self.statistics:
                self.statistics[table_name].row_count = enhanced_stats.row_count
                self.statistics[table_name].page_count = enhanced_stats.page_count
                self.statistics[table_name].avg_row_size = enhanced_stats.avg_row_size
                
                # æ›´æ–°åˆ—ç»Ÿè®¡ä¿¡æ¯
                for col_name, col_stats in enhanced_stats.column_stats.items():
                    self.statistics[table_name].column_stats[col_name] = col_stats
    
    def get_statistics_summary(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯æ‘˜è¦"""
        summary = {
            'enhanced_statistics_enabled': self.enable_enhanced_statistics,
            'statistics_count': len(self.statistics)
        }
        
        if self.enable_enhanced_statistics:
            summary['statistics_collector'] = self.statistics_collector.get_statistics_summary()
        
        return summary
    
    def refresh_statistics(self, table_name: str = None):
        """åˆ·æ–°ç»Ÿè®¡ä¿¡æ¯"""
        if table_name:
            # åˆ·æ–°ç‰¹å®šè¡¨çš„ç»Ÿè®¡ä¿¡æ¯
            if self.enable_enhanced_statistics:
                enhanced_stats = self.statistics_collector.collect_table_statistics(table_name, force_refresh=True)
                
                # æ›´æ–°å†…éƒ¨ç»Ÿè®¡ä¿¡æ¯
                if table_name in self.statistics:
                    self.statistics[table_name].row_count = enhanced_stats.row_count
                    self.statistics[table_name].page_count = enhanced_stats.page_count
                    self.statistics[table_name].avg_row_size = enhanced_stats.avg_row_size
                    
                    # æ›´æ–°åˆ—ç»Ÿè®¡ä¿¡æ¯
                    for col_name, col_stats in enhanced_stats.column_stats.items():
                        self.statistics[table_name].column_stats[col_name] = col_stats
        else:
            # åˆ·æ–°æ‰€æœ‰è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
            self._initialize_statistics()
    
    def _generate_candidate_plans(self, plan: LogicalPlan) -> List[LogicalPlan]:
        """ç”Ÿæˆå€™é€‰æ‰§è¡Œè®¡åˆ’"""
        candidates = [plan]  # åŸå§‹è®¡åˆ’
        
        # 1. ç´¢å¼•é€‰æ‹©ä¼˜åŒ– - ä¸ºæ¯ä¸ªScanæ“ä½œç¬¦ç”Ÿæˆç´¢å¼•æ‰«æå€™é€‰
        index_candidates = self._generate_index_scan_candidates(plan)
        if index_candidates:  # åªæœ‰åœ¨æœ‰ç´¢å¼•å€™é€‰æ—¶æ‰æ·»åŠ 
            candidates.extend(index_candidates)
        
        # 2. è¿æ¥é¡ºåºä¼˜åŒ–ï¼ˆæš‚æ—¶è·³è¿‡ï¼Œå‡å°‘å¼€é”€ï¼‰
        # candidates.extend(self._generate_join_order_candidates(plan))
        
        # 3. è¿æ¥æ–¹æ³•ä¼˜åŒ–
        join_method_candidates = self._generate_join_method_candidates(plan)
        if join_method_candidates:
            candidates.extend(join_method_candidates)
        
        return candidates
    
    def _generate_index_scan_candidates(self, plan: LogicalPlan) -> List[LogicalPlan]:
        """ç”Ÿæˆç´¢å¼•æ‰«æå€™é€‰è®¡åˆ’"""
        candidates = []
        
        # éå†è®¡åˆ’æ ‘ï¼Œæ‰¾åˆ°Scanæ“ä½œç¬¦
        def find_scans(operator):
            if hasattr(operator, 'operator_type') and operator.operator_type.value == 'Scan':
                # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„ç´¢å¼•
                table_name = getattr(operator, 'table_name', '')
                if self.catalog and table_name:
                    table_info = self.catalog.get_table(table_name)
                    if table_info and table_info.indexes:
                        # ä¸ºæ¯ä¸ªç´¢å¼•åˆ›å»ºå€™é€‰è®¡åˆ’
                        for index_name, index_info in table_info.indexes.items():
                            # è·å–ç´¢å¼•åˆ—å
                            if isinstance(index_info, dict):
                                column_name = index_info.get('columns', [index_name])[0]
                            else:
                                column_name = getattr(index_info, 'columns', [index_name])[0]
                            
                            # æŸ¥æ‰¾ç›¸å…³çš„è¿‡æ»¤æ¡ä»¶
                            predicate = self._find_predicate_for_column(plan.root, table_name, column_name)
                            
                            # åªæœ‰åœ¨æœ‰ç›¸å…³è¿‡æ»¤æ¡ä»¶æ—¶æ‰è€ƒè™‘ç´¢å¼•æ‰«æ
                            if not predicate:
                                continue
                            
                            # è®¡ç®—é€‰æ‹©æ€§
                            selectivity = self._calculate_selectivity(table_name, column_name, predicate)
                            
                            # åˆ›å»ºç´¢å¼•æ‰«ææ“ä½œç¬¦
                            idx_scan = IndexScanOperator(
                                table_name=table_name,
                                index_name=index_name,
                                column_name=column_name,
                                predicate=predicate
                            )
                            
                            # è®¾ç½®é€‰æ‹©æ€§å±æ€§
                            idx_scan.selectivity = selectivity
                            
                            # æ›¿æ¢åŸå§‹è®¡åˆ’ä¸­çš„Scanæ“ä½œç¬¦
                            new_plan = self._replace_operator_in_plan(plan, operator, idx_scan)
                            if new_plan:
                                candidates.append(new_plan)
            
            # é€’å½’å¤„ç†å­æ“ä½œç¬¦
            if hasattr(operator, 'children'):
                for child in operator.children:
                    find_scans(child)
        
        find_scans(plan.root)
        return candidates
    
    def _find_predicate_for_column(self, operator, table_name: str, column_name: str) -> Optional[str]:
        """æŸ¥æ‰¾ä¸æŒ‡å®šåˆ—ç›¸å…³çš„è°“è¯æ¡ä»¶"""
        if hasattr(operator, 'operator_type'):
            op_type = operator.operator_type.value
            if op_type == 'Filter':
                # æ£€æŸ¥è¿‡æ»¤æ¡ä»¶æ˜¯å¦æ¶‰åŠæŒ‡å®šåˆ—
                condition = getattr(operator, 'condition', None)
                if condition and column_name in str(condition):
                    return str(condition)
            
            # é€’å½’æ£€æŸ¥å­æ“ä½œç¬¦
            if hasattr(operator, 'children'):
                for child in operator.children:
                    predicate = self._find_predicate_for_column(child, table_name, column_name)
                    if predicate:
                        return predicate
        return None
    
    def _calculate_selectivity(self, table_name: str, column_name: str, predicate: Optional[str]) -> float:
        """è®¡ç®—åˆ—çš„é€‰æ‹©æ€§"""
        if not predicate:
            return 0.5  # é»˜è®¤é€‰æ‹©æ€§
        
        # å°è¯•ä»ç»Ÿè®¡ä¿¡æ¯è·å–çœŸå®çš„é€‰æ‹©æ€§
        if self.catalog:
            try:
                col_stats = self.catalog.get_column_stats(table_name, column_name)
                if col_stats and 'distinct' in col_stats:
                    distinct_count = col_stats['distinct']
                    if '=' in predicate or '==' in predicate:
                        # ç­‰å€¼æŸ¥è¯¢ï¼šä½¿ç”¨çœŸå®distinctå€¼
                        return 1.0 / max(1, distinct_count)
                    elif any(op in predicate for op in ['<', '>', '<=', '>=']):
                        # èŒƒå›´æŸ¥è¯¢ï¼šåŸºäºdistinctå€¼ä¼°ç®—
                        return max(0.01, min(0.5, 1.0 / max(1, distinct_count) * 10))
            except Exception:
                pass
        
        # å¦‚æœæ— æ³•è·å–çœŸå®ç»Ÿè®¡ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—
        if '=' in predicate or '==' in predicate:
            return 0.1  # ç­‰å€¼æŸ¥è¯¢ï¼Œå‡è®¾10%é€‰æ‹©æ€§
        elif any(op in predicate for op in ['<', '>', '<=', '>=']):
            return 0.1  # èŒƒå›´æŸ¥è¯¢ï¼Œä¸­ç­‰é€‰æ‹©æ€§
        else:
            return 0.5  # å…¶ä»–æƒ…å†µï¼Œä½é€‰æ‹©æ€§
    
    def _generate_join_order_candidates(self, plan: LogicalPlan) -> List[LogicalPlan]:
        """ç”Ÿæˆè¿æ¥é¡ºåºå€™é€‰è®¡åˆ’"""
        # è·å–æ‰€æœ‰è¿æ¥èŠ‚ç‚¹
        join_nodes = []
        self._collect_join_nodes(plan, join_nodes)
        
        if len(join_nodes) <= 1:
            return [plan]
        
        # ç”Ÿæˆä¸åŒçš„è¿æ¥é¡ºåº
        candidates = []
        tables = [node.table_name for node in join_nodes]
        
        # ç”Ÿæˆæ‰€æœ‰å¯èƒ½çš„è¿æ¥é¡ºåºæ’åˆ—
        from itertools import permutations
        for perm in permutations(tables):
            if perm != tuple(tables):  # æ’é™¤åŸå§‹é¡ºåº
                new_plan = self._reorder_joins(plan, perm)
                if new_plan:
                    candidates.append(new_plan)
        
        return candidates
    
    def _collect_join_nodes(self, plan: LogicalPlan, join_nodes: List):
        """é€’å½’æ”¶é›†æ‰€æœ‰è¿æ¥èŠ‚ç‚¹"""
        if hasattr(plan.root, 'left_child') and plan.root.left_child:
            left_plan = LogicalPlan(plan.root.left_child)
            self._collect_join_nodes(left_plan, join_nodes)
        if hasattr(plan.root, 'right_child') and plan.root.right_child:
            right_plan = LogicalPlan(plan.root.right_child)
            self._collect_join_nodes(right_plan, join_nodes)
        if plan.node_type == 'Join':
            join_nodes.append(plan)
    
    def _reorder_joins(self, plan: LogicalPlan, new_order: tuple) -> Optional[LogicalPlan]:
        """é‡æ–°æ’åºè¿æ¥èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºæ–°çš„è¿æ¥è®¡åˆ’
            new_plan = LogicalPlan('Join')
            new_plan.left_child = LogicalPlan('SeqScan')
            new_plan.left_child.table_name = new_order[0]
            
            current = new_plan
            for i in range(1, len(new_order)):
                current.right_child = LogicalPlan('SeqScan')
                current.right_child.table_name = new_order[i]
                if i < len(new_order) - 1:
                    current = LogicalPlan('Join')
                    current.left_child = current.right_child
            
            return new_plan
        except Exception as e:
            self.logger.warning(f"æ— æ³•é‡æ–°æ’åºè¿æ¥: {e}")
            return None
    
    def _generate_join_method_candidates(self, plan: LogicalPlan) -> List[LogicalPlan]:
        """ç”Ÿæˆè¿æ¥æ–¹æ³•å€™é€‰è®¡åˆ’"""
        candidates = []
        
        # æŸ¥æ‰¾æ‰€æœ‰è¿æ¥æ“ä½œç¬¦
        join_operators = self._find_join_operators(plan.root)
        
        for join_op in join_operators:
            # ä¸ºæ¯ä¸ªè¿æ¥æ“ä½œç¬¦ç”Ÿæˆä¸åŒçš„è¿æ¥æ–¹æ³•å€™é€‰
            for join_method in [JoinMethod.HASH_JOIN, JoinMethod.SORT_MERGE]:
                if self._is_join_method_applicable(join_op, join_method):
                    new_plan = self._create_join_method_candidate(plan, join_op, join_method)
                    if new_plan:
                        candidates.append(new_plan)
        
        return candidates
    
    def _find_join_operators(self, operator) -> List:
        """é€’å½’æŸ¥æ‰¾æ‰€æœ‰è¿æ¥æ“ä½œç¬¦"""
        join_ops = []
        
        if hasattr(operator, 'operator_type') and operator.operator_type.value == 'Join':
            join_ops.append(operator)
        
        # é€’å½’æŸ¥æ‰¾å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                join_ops.extend(self._find_join_operators(child))
        
        return join_ops
    
    def _is_join_method_applicable(self, join_op, join_method: JoinMethod) -> bool:
        """åˆ¤æ–­è¿æ¥æ–¹æ³•æ˜¯å¦é€‚ç”¨äºç»™å®šçš„è¿æ¥æ“ä½œç¬¦"""
        if not hasattr(join_op, 'left_child') or not hasattr(join_op, 'right_child'):
            return False
        
        # è·å–å·¦å³å­è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
        left_stats = self._get_table_stats_from_operator(join_op.left_child)
        right_stats = self._get_table_stats_from_operator(join_op.right_child)
        
        if not left_stats or not right_stats:
            return False
        
        if join_method == JoinMethod.HASH_JOIN:
            # å“ˆå¸Œè¿æ¥é€‚ç”¨äºï¼šå°è¡¨ä½œä¸ºæ„å»ºè¡¨ï¼Œå¤§è¡¨ä½œä¸ºæ¢æµ‹è¡¨
            # æˆ–è€…å†…å­˜è¶³å¤Ÿå®¹çº³è¾ƒå°çš„è¡¨
            smaller_table = min(left_stats.row_count, right_stats.row_count)
            return smaller_table < 10000  # å‡è®¾å†…å­˜å¯ä»¥å®¹çº³10000è¡Œ
        
        elif join_method == JoinMethod.SORT_MERGE:
            # æ’åºåˆå¹¶è¿æ¥é€‚ç”¨äºï¼šæ•°æ®å·²ç»æœ‰åºæˆ–æ¥è¿‘æœ‰åº
            # æˆ–è€…è¿æ¥æ¡ä»¶æ¶‰åŠèŒƒå›´æ¯”è¾ƒ
            condition = getattr(join_op, 'condition', '')
            return any(op in str(condition) for op in ['<', '>', '<=', '>='])
        
        return True
    
    def _get_table_stats_from_operator(self, operator) -> Optional[Statistics]:
        """ä»æ“ä½œç¬¦è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        if hasattr(operator, 'table_name'):
            table_name = operator.table_name
            return self.statistics.get(table_name)
        return None
    
    def _create_join_method_candidate(self, original_plan: LogicalPlan, join_op, join_method: JoinMethod) -> Optional[LogicalPlan]:
        """åˆ›å»ºä½¿ç”¨ç‰¹å®šè¿æ¥æ–¹æ³•çš„å€™é€‰è®¡åˆ’"""
        try:
            # åˆ›å»ºæ–°çš„è¿æ¥æ“ä½œç¬¦
            new_join_op = JoinOperator(
                join_type=join_op.join_type,
                condition=join_op.condition,
                join_method=join_method
            )
            
            # å¤åˆ¶å­æ“ä½œç¬¦
            if hasattr(join_op, 'left_child'):
                new_join_op.left_child = join_op.left_child
            if hasattr(join_op, 'right_child'):
                new_join_op.right_child = join_op.right_child
            
            # åˆ›å»ºæ–°çš„è®¡åˆ’
            new_plan = LogicalPlan(new_join_op)
            return new_plan
        except Exception as e:
            if self.demo_mode:
                print(f"   âš ï¸ åˆ›å»ºè¿æ¥æ–¹æ³•å€™é€‰å¤±è´¥: {e}")
            return None
    
    def _replace_operator_in_plan(self, plan: LogicalPlan, old_op, new_op) -> LogicalPlan:
        """åœ¨è®¡åˆ’ä¸­æ›¿æ¢æ“ä½œç¬¦"""
        # ç®€åŒ–å®ç°ï¼šåˆ›å»ºæ–°çš„è®¡åˆ’
        try:
            # è¿™é‡Œéœ€è¦æ·±åº¦å¤åˆ¶è®¡åˆ’å¹¶æ›¿æ¢æ“ä½œç¬¦
            # ä¸ºäº†ç®€åŒ–ï¼Œæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ–°çš„è®¡åˆ’
            return LogicalPlan(new_op)
        except:
            return None
    
    def _initialize_statistics(self):
        """åˆå§‹åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        for table_name, table_info in self.symbol_table.tables.items():
            if self.enable_enhanced_statistics:
                # ä½¿ç”¨å¢å¼ºç»Ÿè®¡ä¿¡æ¯æ”¶é›†å™¨
                enhanced_stats = self.statistics_collector.collect_table_statistics(table_name)
                
                # è½¬æ¢ä¸ºå…¼å®¹çš„Statisticsæ ¼å¼
                stats = Statistics(
                    table_name=table_name,
                    row_count=enhanced_stats.row_count,
                    page_count=enhanced_stats.page_count,
                    avg_row_size=enhanced_stats.avg_row_size
                )
                
                # è½¬æ¢åˆ—ç»Ÿè®¡ä¿¡æ¯
                for col_name, col_stats in enhanced_stats.column_stats.items():
                    stats.column_stats[col_name] = col_stats
                
                self.statistics[table_name] = stats
            else:
                # ä½¿ç”¨åŸæœ‰çš„ç®€åŒ–ç»Ÿè®¡ä¿¡æ¯æ”¶é›†
                stats = Statistics(
                    table_name=table_name,
                    row_count=self._estimate_row_count(table_name),
                    page_count=self._estimate_page_count(table_name),
                    avg_row_size=self._estimate_avg_row_size(table_info)
                )
                
                # ä¸ºæ¯åˆ—ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯
                for column in table_info.columns:
                    col_stats = ColumnStatistics(
                        column_name=column.name,
                        distinct_count=self._estimate_distinct_count(table_name, column.name),
                        null_count=0,  # ç®€åŒ–å®ç°
                        min_value=None,
                        max_value=None
                    )
                    stats.column_stats[column.name] = col_stats
                
                self.statistics[table_name] = stats
    
    def _estimate_row_count(self, table_name: str) -> int:
        """ä¼˜å…ˆä½¿ç”¨ Catalog çœŸå®ç»Ÿè®¡ï¼Œå¦åˆ™ä½¿ç”¨é»˜è®¤ä¼°ç®—"""
        if hasattr(self, 'catalog') and self.catalog is not None:
            try:
                t = self.catalog.get_table(table_name)
                catalog_row_count = int(getattr(t, 'row_count', 0))
                if catalog_row_count > 0:
                    return catalog_row_count
            except Exception:
                pass
        # å›é€€ä¼°ç®— - ä½¿ç”¨æ›´çœŸå®çš„é»˜è®¤å€¼
        if 'users' in table_name.lower():
            return 10000
        elif 'orders' in table_name.lower():
            return 100000
        elif 'products' in table_name.lower():
            return 5000
        elif 'customers' in table_name.lower():
            return 50000
        elif 'test_table' in table_name.lower():
            return 1000
        else:
            return 1000
    
    def _estimate_page_count(self, table_name: str) -> int:
        """ä¼˜å…ˆä½¿ç”¨ Catalog çœŸå®ç»Ÿè®¡ï¼Œå¦åˆ™æŒ‰è¡Œæ•°ä¼°ç®—é¡µæ•°"""
        if hasattr(self, 'catalog') and self.catalog is not None:
            try:
                t = self.catalog.get_table(table_name)
                pc = int(getattr(t, 'page_count', 0))
                if pc > 0:
                    return pc
            except Exception:
                pass
        row_count = self._estimate_row_count(table_name)
        rows_per_page = 100  # å‡è®¾æ¯é¡µ100è¡Œ
        return max(1, math.ceil(row_count / rows_per_page))
    
    def _estimate_avg_row_size(self, table_info: TableInfo) -> float:
        """ä¼°ç®—å¹³å‡è¡Œå¤§å°"""
        total_size = 0
        for column in table_info.columns:
            if column.data_type.value == 'INT':
                total_size += 4
            elif column.data_type.value == 'VARCHAR':
                total_size += 50  # å‡è®¾å¹³å‡50å­—ç¬¦
            elif column.data_type.value == 'DECIMAL':
                total_size += 8
            else:
                total_size += 4
        return total_size
    
    def _estimate_distinct_count(self, table_name: str, column_name: str) -> int:
        """ä¼˜å…ˆä½¿ç”¨ catalog ä¸­çš„çœŸå® distinctï¼Œå¦åˆ™ä¼°ç®—åˆ—çš„å”¯ä¸€å€¼æ•°é‡"""
        if hasattr(self, 'catalog') and self.catalog is not None:
            try:
                cs = self.catalog.get_column_stats(table_name, column_name)
                if cs and isinstance(cs.get('distinct'), int) and cs['distinct'] > 0:
                    return cs['distinct']
            except Exception:
                pass
        row_count = self._estimate_row_count(table_name)
        return max(1, row_count // 2)
    
    def _generate_optimization_report(self, original_plan: LogicalPlan, optimized_plan: LogicalPlan):
        """ç”Ÿæˆä¼˜åŒ–æŠ¥å‘Š"""
        print("\nğŸ“‹ ä¼˜åŒ–æŠ¥å‘Š:")
        print("   " + "="*50)
        
        # è®¡ç®—ä¼˜åŒ–æ•ˆæœ
        original_cost = self.cost_model.calculate_cost(original_plan, self.statistics)
        optimized_cost = self.cost_model.calculate_cost(optimized_plan, self.statistics)
        
        improvement = ((original_cost.total_cost - optimized_cost.total_cost) / original_cost.total_cost) * 100
        
        print(f"   åŸå§‹è®¡åˆ’æˆæœ¬: {original_cost.total_cost:.2f}")
        print(f"   ä¼˜åŒ–åæˆæœ¬: {optimized_cost.total_cost:.2f}")
        print(f"   æ€§èƒ½æå‡: {improvement:.1f}%")
        
        # æˆæœ¬åˆ†è§£
        print(f"\n   ğŸ“Š æˆæœ¬åˆ†è§£:")
        print(f"     I/Oæˆæœ¬: {optimized_cost.io_cost:.2f}")
        print(f"     CPUæˆæœ¬: {optimized_cost.cpu_cost:.2f}")
        print(f"     å†…å­˜æˆæœ¬: {optimized_cost.memory_cost:.2f}")

class CostModel:
    """æˆæœ¬æ¨¡å‹ - æ”¯æŒåŸºäºçœŸå®ç»Ÿè®¡æ•°æ®çš„åŠ¨æ€æˆæœ¬è®¡ç®—"""
    
    def __init__(self, catalog_manager=None, adaptive_params=None):
        # åŸºç¡€æˆæœ¬å‚æ•°ï¼ˆå¯æ ¹æ®ç¡¬ä»¶å’Œç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´ï¼‰
        self.io_cost_per_page = 1.0      # æ¯é¡µI/Oæˆæœ¬
        self.cpu_cost_per_row = 0.001    # æ¯è¡ŒCPUæˆæœ¬
        self.memory_cost_per_page = 0.1  # æ¯é¡µå†…å­˜æˆæœ¬
        
        # ç´¢å¼•ç›¸å…³æˆæœ¬å‚æ•°
        self.index_seek_cost_per_level = 0.1  # æ¯å±‚ç´¢å¼•æŸ¥æ‰¾æˆæœ¬
        self.index_scan_cost_per_row = 0.01   # æ¯è¡Œç´¢å¼•æ‰«ææˆæœ¬
        self.index_fetch_cost_per_page = 0.1  # æ¯é¡µå›è¡¨æˆæœ¬
        self.index_cpu_cost_per_row = 0.0001  # æ¯è¡Œç´¢å¼•CPUæˆæœ¬
        self.index_memory_cost = 0.05         # ç´¢å¼•ç¼“å­˜æˆæœ¬
        
        # ä¿å­˜catalogå¼•ç”¨
        self.catalog = catalog_manager
        
        # è‡ªé€‚åº”å‚æ•°
        self.adaptive_params = adaptive_params
        if self.adaptive_params:
            self._apply_adaptive_parameters()
    
    def _apply_adaptive_parameters(self):
        """åº”ç”¨è‡ªé€‚åº”å‚æ•°"""
        if self.adaptive_params:
            self.io_cost_per_page = self.adaptive_params.io_cost_per_page
            self.cpu_cost_per_row = self.adaptive_params.cpu_cost_per_row
            self.memory_cost_per_page = self.adaptive_params.memory_cost_per_page
            self.index_seek_cost_per_level = self.adaptive_params.index_seek_cost_per_level
            self.index_scan_cost_per_row = self.adaptive_params.index_scan_cost_per_row
            self.index_fetch_cost_per_page = self.adaptive_params.index_fetch_cost_per_page
            self.index_cpu_cost_per_row = self.adaptive_params.index_cpu_cost_per_row
            self.index_memory_cost = self.adaptive_params.index_memory_cost
    
    def calculate_cost(self, plan: LogicalPlan, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—æ‰§è¡Œè®¡åˆ’æˆæœ¬"""
        return self._calculate_operator_cost(plan.root, statistics)
    
    def _calculate_operator_cost(self, operator: LogicalOperator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—å•ä¸ªæ“ä½œç¬¦æˆæœ¬ï¼ˆé€’å½’è®¡ç®—å­æ“ä½œç¬¦ï¼‰"""
        if hasattr(operator, 'operator_type'):
            op_type = operator.operator_type.value
        else:
            op_type = type(operator).__name__
        
        # è®¡ç®—å½“å‰æ“ä½œç¬¦çš„æˆæœ¬
        if op_type == 'Scan':
            current_cost = self._calculate_scan_cost(operator, statistics)
        elif op_type == 'IndexScan':
            current_cost = self._calculate_index_scan_cost(operator, statistics)
        elif op_type == 'Filter':
            current_cost = self._calculate_filter_cost(operator, statistics)
        elif op_type == 'Project':
            current_cost = self._calculate_project_cost(operator, statistics)
        elif op_type == 'Join':
            current_cost = self._calculate_join_cost(operator, statistics)
        else:
            current_cost = CostInfo(io_cost=1.0, cpu_cost=1.0, memory_cost=0.5)
        
        # é€’å½’è®¡ç®—å­æ“ä½œç¬¦çš„æˆæœ¬
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                child_cost = self._calculate_operator_cost(child, statistics)
                # ç´¯åŠ å­æ“ä½œç¬¦çš„æˆæœ¬
                current_cost.io_cost += child_cost.io_cost
                current_cost.cpu_cost += child_cost.cpu_cost
                current_cost.memory_cost += child_cost.memory_cost
                current_cost.total_cost += child_cost.total_cost
        
        return current_cost
    
    def _calculate_scan_cost(self, operator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—å…¨è¡¨æ‰«ææˆæœ¬ - åŸºäºçœŸå®ç»Ÿè®¡æ•°æ®"""
        table_name = getattr(operator, 'table_name', 'unknown')
        stats = statistics.get(table_name, Statistics(table_name))
        
        # ç¡®ä¿æœ‰åˆç†çš„ç»Ÿè®¡ä¿¡æ¯
        row_count = max(1, stats.row_count)
        page_count = max(1, stats.page_count)
        
        # I/Oæˆæœ¬ï¼šå…¨è¡¨æ‰«æéœ€è¦è¯»å–æ‰€æœ‰é¡µï¼ˆé¡ºåºI/Oï¼Œç›¸å¯¹é«˜æ•ˆï¼‰
        io_cost = page_count * self.io_cost_per_page
        
        # CPUæˆæœ¬ï¼šéœ€è¦å¤„ç†æ‰€æœ‰è¡Œï¼ˆåŒ…æ‹¬ä¸åŒ¹é…çš„è¡Œï¼‰
        cpu_cost = row_count * self.cpu_cost_per_row
        
        # å†…å­˜æˆæœ¬ï¼šéœ€è¦ç¼“å­˜æ•°æ®é¡µ
        memory_cost = page_count * self.memory_cost_per_page
        
        # å…¨è¡¨æ‰«æçš„å›ºæœ‰å¼€é”€ï¼šéœ€è¦æ‰«ææ•´ä¸ªè¡¨ï¼Œæ— è®ºé€‰æ‹©æ€§å¦‚ä½•
        # è¿™æ˜¯å…¨è¡¨æ‰«æçš„ä¸»è¦åŠ£åŠ¿
        return CostInfo(
            io_cost=io_cost,
            cpu_cost=cpu_cost,
            memory_cost=memory_cost
        )

    def _calculate_index_scan_cost(self, operator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—ç´¢å¼•æ‰«ææˆæœ¬ - åŸºäºçœŸå®ç»Ÿè®¡æ•°æ®å’ŒåŠ¨æ€å‚æ•°"""
        table_name = getattr(operator, 'table_name', 'unknown')
        stats = statistics.get(table_name, Statistics(table_name))
        row_count = max(1, stats.row_count)
        page_count = max(1, stats.page_count)
        
        # ä¼˜å…ˆä½¿ç”¨çœŸå®çš„é€‰æ‹©æ€§ä¼°ç®—
        sel = getattr(operator, 'selectivity', None)
        if sel is None:
            # æ ¹æ®æ“ä½œç¬¦ç±»å‹å’ŒçœŸå®ç»Ÿè®¡æ•°æ®ä¼°ç®—é€‰æ‹©æ€§
            predicate = getattr(operator, 'predicate', '') or ''
            column_name = getattr(operator, 'column_name', '')
            
            # å°è¯•ä»ç»Ÿè®¡ä¿¡æ¯è·å–çœŸå®çš„é€‰æ‹©æ€§
            if hasattr(self, 'catalog') and self.catalog:
                try:
                    col_stats = self.catalog.get_column_stats(table_name, column_name)
                    if col_stats and 'distinct' in col_stats:
                        distinct_count = col_stats['distinct']
                        if '=' in predicate or '==' in predicate:
                            # ç­‰å€¼æŸ¥è¯¢ï¼šä½¿ç”¨çœŸå®distinctå€¼
                            sel = 1.0 / max(1, distinct_count)
                        elif any(op in predicate for op in ['<', '>', '<=', '>=']):
                            # èŒƒå›´æŸ¥è¯¢ï¼šåŸºäºdistinctå€¼ä¼°ç®—
                            sel = max(0.01, min(0.5, 1.0 / max(1, distinct_count) * 10))
                        else:
                            sel = 0.5
                except Exception:
                    pass
            
            # å¦‚æœæ— æ³•è·å–çœŸå®ç»Ÿè®¡ï¼Œä½¿ç”¨é»˜è®¤ä¼°ç®—
            if sel is None:
                if '=' in predicate or '==' in predicate:
                    distinct_count = max(1, row_count // 10)  # å‡è®¾æœ‰10%çš„å”¯ä¸€å€¼
                    sel = 1.0 / distinct_count
                elif any(op in predicate for op in ['<', '>', '<=', '>=']):
                    sel = 0.1  # èŒƒå›´æŸ¥è¯¢ï¼Œä¸­ç­‰é€‰æ‹©æ€§
                else:
                    sel = 0.5  # å…¶ä»–æƒ…å†µï¼Œä½é€‰æ‹©æ€§
        
        matched = max(1.0, row_count * sel)
        # å¢åŠ è°ƒè¯•æ—¥å¿—éªŒè¯é€‰æ‹©æ€§å‚æ•°
        print(f"[DEBUG] ç´¢å¼•{operator.index_name if hasattr(operator,'index_name') else ''} é€‰æ‹©æ€§: {sel:.4f} åŒ¹é…è¡Œæ•°: {matched}")
        
        # æ”¹è¿›çš„ç´¢å¼•æ‰«ææˆæœ¬æ¨¡å‹
        # 1. ç´¢å¼•æŸ¥æ‰¾æˆæœ¬ï¼šB+æ ‘é«˜åº¦ * å•æ¬¡I/Oæˆæœ¬ï¼ˆç´¢å¼•æŸ¥æ‰¾é€šå¸¸å¾ˆå¿«ï¼‰
        index_height = max(1, math.ceil(math.log2(max(2, row_count))))
        seek_cost = index_height * self.index_seek_cost_per_level * 0.5  # ç´¢å¼•æŸ¥æ‰¾ä¼˜åŒ–
        
        # 2. ç´¢å¼•æ‰«ææˆæœ¬ï¼šåŒ¹é…çš„ç´¢å¼•é¡¹æ•°é‡ï¼ˆç´¢å¼•æ‰«ææ¯”å…¨è¡¨æ‰«æå¿«ï¼‰
        scan_cost = matched * self.index_scan_cost_per_row * 0.3  # ç´¢å¼•æ‰«æä¼˜åŒ–
        
        # 3. å›è¡¨æˆæœ¬ï¼šä»ç´¢å¼•è·å–æ•°æ®é¡µï¼ˆè¿™æ˜¯ä¸»è¦å¼€é”€ï¼‰
        pages_to_fetch = max(1, math.ceil(matched / 100))  # å‡è®¾æ¯é¡µ100è¡Œ
        fetch_cost = pages_to_fetch * self.index_fetch_cost_per_page
        
        # 4. CPUæˆæœ¬ï¼šç´¢å¼•æ¯”è¾ƒå’Œæ•°æ®å¤„ç†ï¼ˆç´¢å¼•æ¯”è¾ƒæ¯”å…¨è¡¨æ‰«æå¿«ï¼‰
        cpu_cost = matched * self.index_cpu_cost_per_row * 0.2  # CPUä¼˜åŒ–
        
        # 5. é€‰æ‹©æ€§ä¼˜åŒ–ï¼šé«˜é€‰æ‹©æ€§æ—¶ç´¢å¼•ä¼˜åŠ¿æ›´æ˜æ˜¾
        selectivity_factor = 1.0
        if sel < 0.1:  # é«˜é€‰æ‹©æ€§ï¼ˆ<10%ï¼‰
            selectivity_factor = 0.3
        elif sel < 0.3:  # ä¸­ç­‰é€‰æ‹©æ€§ï¼ˆ<30%ï¼‰
            selectivity_factor = 0.6
        elif sel < 0.7:  # ä½é€‰æ‹©æ€§ï¼ˆ<70%ï¼‰
            selectivity_factor = 0.8
        # é€‰æ‹©æ€§>=70%æ—¶ï¼Œç´¢å¼•ä¼˜åŠ¿ä¸æ˜æ˜¾ï¼Œæ¥è¿‘å…¨è¡¨æ‰«æ
        
        io_cost = (seek_cost + scan_cost + fetch_cost) * selectivity_factor
        memory_cost = self.index_memory_cost * 0.5  # ç´¢å¼•å†…å­˜å ç”¨è¾ƒå°‘
        
        return CostInfo(io_cost=io_cost, cpu_cost=cpu_cost, memory_cost=memory_cost)
    
    def _calculate_filter_cost(self, operator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—è¿‡æ»¤æˆæœ¬"""
        # è¿‡æ»¤æˆæœ¬ä¸»è¦æ¥è‡ªCPU
        condition = getattr(operator, 'condition', None)
        if condition:
            # ç®€åŒ–ï¼šå‡è®¾è¿‡æ»¤æ¡ä»¶å¤æ‚åº¦ä¸ºä¸­ç­‰
            cpu_cost = 0.01
        else:
            cpu_cost = 0.001
        
        return CostInfo(io_cost=0.0, cpu_cost=cpu_cost, memory_cost=0.05)
    
    def _calculate_project_cost(self, operator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—æŠ•å½±æˆæœ¬"""
        # æŠ•å½±æˆæœ¬è¾ƒä½
        columns = getattr(operator, 'columns', [])
        cpu_cost = len(columns) * 0.001
        
        return CostInfo(io_cost=0.0, cpu_cost=cpu_cost, memory_cost=0.02)
    
    def _calculate_join_cost(self, operator, statistics: Dict[str, Statistics]) -> CostInfo:
        """è®¡ç®—è¿æ¥æˆæœ¬ - æ”¯æŒä¸åŒè¿æ¥æ–¹æ³•"""
        join_method = getattr(operator, 'join_method', JoinMethod.NESTED_LOOP)
        
        # è·å–å·¦å³å­è¡¨çš„ç»Ÿè®¡ä¿¡æ¯
        left_stats = None
        right_stats = None
        
        if hasattr(operator, 'left_child') and operator.left_child:
            left_table_name = getattr(operator.left_child, 'table_name', None)
            if left_table_name:
                left_stats = statistics.get(left_table_name)
        
        if hasattr(operator, 'right_child') and operator.right_child:
            right_table_name = getattr(operator.right_child, 'table_name', None)
            if right_table_name:
                right_stats = statistics.get(right_table_name)
        
        if not left_stats or not right_stats:
            # å›é€€åˆ°é»˜è®¤æˆæœ¬
            return CostInfo(io_cost=0.0, cpu_cost=0.1, memory_cost=0.2)
        
        left_rows = left_stats.row_count
        right_rows = right_stats.row_count
        
        if join_method == JoinMethod.NESTED_LOOP:
            # åµŒå¥—å¾ªç¯è¿æ¥ï¼šO(M * N)
            cpu_cost = left_rows * right_rows * 0.0001
            memory_cost = 0.1  # åªéœ€è¦å°‘é‡å†…å­˜
            io_cost = 0.0  # å‡è®¾æ•°æ®åœ¨å†…å­˜ä¸­
            
        elif join_method == JoinMethod.HASH_JOIN:
            # å“ˆå¸Œè¿æ¥ï¼šO(M + N)
            # æ„å»ºé˜¶æ®µï¼šæ‰«æå°è¡¨ï¼Œæ„å»ºå“ˆå¸Œè¡¨
            build_cost = min(left_rows, right_rows) * 0.001
            # æ¢æµ‹é˜¶æ®µï¼šæ‰«æå¤§è¡¨ï¼ŒæŸ¥æ‰¾å“ˆå¸Œè¡¨
            probe_cost = max(left_rows, right_rows) * 0.0005
            cpu_cost = build_cost + probe_cost
            # å†…å­˜æˆæœ¬ï¼šå“ˆå¸Œè¡¨å¤§å°
            memory_cost = min(left_rows, right_rows) * 0.01
            io_cost = 0.0
            
        elif join_method == JoinMethod.SORT_MERGE:
            # æ’åºåˆå¹¶è¿æ¥ï¼šO(M log M + N log N + M + N)
            left_sort_cost = left_rows * math.log2(max(1, left_rows)) * 0.0001
            right_sort_cost = right_rows * math.log2(max(1, right_rows)) * 0.0001
            merge_cost = (left_rows + right_rows) * 0.0001
            cpu_cost = left_sort_cost + right_sort_cost + merge_cost
            # æ’åºéœ€è¦ä¸´æ—¶å­˜å‚¨ç©ºé—´
            memory_cost = (left_rows + right_rows) * 0.005
            io_cost = 0.0
            
        else:
            # é»˜è®¤æˆæœ¬
            cpu_cost = 0.1
            memory_cost = 0.2
            io_cost = 0.0
        
        return CostInfo(io_cost=io_cost, cpu_cost=cpu_cost, memory_cost=memory_cost)
    
    def _get_table_stats_from_operator(self, operator) -> Optional[Statistics]:
        """ä»æ“ä½œç¬¦è·å–è¡¨ç»Ÿè®¡ä¿¡æ¯"""
        if hasattr(operator, 'table_name'):
            table_name = operator.table_name
            # è¿™é‡Œéœ€è¦ä»statisticså‚æ•°ä¸­è·å–ï¼Œä½†å½“å‰æ–¹æ³•ç­¾åä¸åŒ…å«statistics
            # ç®€åŒ–å®ç°ï¼šè¿”å›None
            return None
        return None

class RuleEngine:
    """è§„åˆ™å¼•æ“"""
    
    def __init__(self, catalog_manager: CatalogManager | None = None, statistics_supplier=None):
        self.rules = [
            self._rule_use_index_if_available,
            self._rule_optimize_order_by_with_index,
            self._rule_push_predicates_down,
            self._rule_eliminate_redundant_operations,
            self._rule_optimize_join_order,
            self._rule_constant_folding,
            self._rule_subquery_optimization,
            self._rule_predicate_simplification,
            self._rule_column_elimination
        ]
        self.catalog = catalog_manager
        # ç®€åŒ–çš„èŒƒå›´é€‰æ‹©é˜ˆå€¼ï¼ˆå‘½ä¸­è¡Œæ¯”ä¾‹ < 0.1 åˆ™å€¾å‘ç´¢å¼•ï¼‰
        self.range_selectivity_threshold = 0.1
        self._statistics_supplier = statistics_supplier or (lambda: {})
        # å†³ç­–è®°å½•ç”¨äºå¯è§†åŒ–
        self.decisions: List[Dict[str, Any]] = []
    
    def optimize(self, plan: LogicalPlan) -> LogicalPlan:
        """åº”ç”¨ä¼˜åŒ–è§„åˆ™"""
        optimized_plan = plan
        
        for rule in self.rules:
            optimized_plan = rule(optimized_plan)
        
        return optimized_plan
    
    def _rule_use_index_if_available(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šå¦‚æœ WHERE æ¡ä»¶åˆ—å­˜åœ¨ç´¢å¼•ï¼Œå°† Scan+Filter æ”¹ä¸º IndexScanã€‚
        æ”¯æŒå¤æ‚ç»“æ„ï¼šLIMIT(ORDER_BY(PROJECT(FILTER(SCAN))))ç­‰
        """
        # é€’å½’æŸ¥æ‰¾å¹¶æ›¿æ¢Filter(Scan)æ¨¡å¼ï¼Œä¿ç•™å…¶ä»–ç®—å­
        self._replace_filter_scan_with_index_scan(plan.root, plan)
        return plan
    
    def _find_parent_of_node(self, root, target_node):
        """æŸ¥æ‰¾ç›®æ ‡èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹"""
        if not hasattr(root, 'children') or not root.children:
            return None
        
        for child in root.children:
            if child is target_node:
                return root
            parent = self._find_parent_of_node(child, target_node)
            if parent:
                return parent
        return None
    
    def _rule_optimize_order_by_with_index(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šå¯¹äºORDER BYæŸ¥è¯¢ï¼Œå¦‚æœORDER BYçš„åˆ—æœ‰ç´¢å¼•ï¼Œä½¿ç”¨ç´¢å¼•æ‰«æä»£æ›¿å…¨è¡¨æ‰«æ+æ’åº"""
        from .logical_operators import IndexScanOperator
        
        # æŸ¥æ‰¾ORDER BYç®—å­
        order_by_node = self._find_order_by_node(plan.root)
        if not order_by_node:
            print("[DEBUG] æ²¡æœ‰æ‰¾åˆ°ORDER BYç®—å­")
            return plan
        
        # æ£€æŸ¥ORDER BYä¸‹æ˜¯å¦æœ‰SCANç®—å­
        scan_node = self._find_scan_under_order_by(order_by_node)
        if not scan_node:
            return plan
        
        # è·å–ORDER BYçš„åˆ—ä¿¡æ¯
        if not hasattr(order_by_node, 'order_items') or not order_by_node.order_items:
            return plan
        
        # ç›®å‰åªä¼˜åŒ–å•åˆ—ORDER BY
        if len(order_by_node.order_items) != 1:
            return plan
        
        order_item = order_by_node.order_items[0]
        order_column = order_item['column']
        order_direction = order_item.get('direction', 'ASC')
        
        # æ£€æŸ¥è¯¥åˆ—æ˜¯å¦æœ‰ç´¢å¼•
        table_name = scan_node.table_name
        if not self.catalog:
            return plan
        
        table_info = self.catalog.get_table(table_name)
        if not table_info or not table_info.indexes:
            return plan
        
        # æŸ¥æ‰¾åŒ¹é…çš„ç´¢å¼•
        matching_index = None
        for index_name, index_info in table_info.indexes.items():
            if isinstance(index_info, dict):
                index_columns = (index_info.get('columns') or 
                               index_info.get('column_names') or 
                               [index_name])
            else:
                index_columns = (getattr(index_info, 'columns', None) or 
                               getattr(index_info, 'column_names', None) or
                               [index_name])
            
            # æ£€æŸ¥ç´¢å¼•æ˜¯å¦åŒ…å«ORDER BYçš„åˆ—
            if index_columns and index_columns[0] == order_column:
                matching_index = index_name
                break
        
        if not matching_index:
            return plan
        
        # åˆ›å»ºIndexScanæ¥æ›¿æ¢Scanï¼Œå¹¶ç§»é™¤OrderByç®—å­
        idx_scan = IndexScanOperator(
            table_name=table_name,
            index_name=matching_index,
            column_name=order_column,
            predicate=None  # æ²¡æœ‰WHEREæ¡ä»¶
        )
        
        # è®¾ç½®ç´¢å¼•æ‰«æçš„æ’åºæ–¹å‘
        setattr(idx_scan, 'order_direction', order_direction)
        
        # æ›¿æ¢ç®—å­æ ‘ç»“æ„ï¼šä¿ç•™PROJECTç­‰å…¶ä»–ç®—å­ï¼Œåªæ›¿æ¢ORDER BY -> SCANä¸ºIndexScan
        # æ‰¾åˆ°ORDER BYçš„å­ç®—å­ï¼ˆé€šå¸¸æ˜¯PROJECTï¼‰
        order_by_children = []
        if hasattr(order_by_node, 'children') and order_by_node.children:
            for child in order_by_node.children:
                if child is not scan_node:  # ä¿ç•™éSCANçš„å­ç®—å­
                    order_by_children.append(child)
        
        # å°†ä¿ç•™çš„å­ç®—å­è¿æ¥åˆ°IndexScan
        for child in order_by_children:
            # åœ¨å­ç®—å­ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢SCAN
            self._replace_scan_with_index_scan(child, scan_node, idx_scan)
        
        # æ›¿æ¢ORDER BYèŠ‚ç‚¹
        parent = self._find_parent_of_node(plan.root, order_by_node)
        if parent:
            # ORDER BYæœ‰çˆ¶èŠ‚ç‚¹
            for i, child in enumerate(parent.children):
                if child is order_by_node:
                    if order_by_children:
                        # ç”¨ç¬¬ä¸€ä¸ªå­ç®—å­æ›¿æ¢ORDER BY
                        parent.children[i] = order_by_children[0]
                    else:
                        # æ²¡æœ‰å­ç®—å­ï¼Œç›´æ¥ç”¨IndexScanæ›¿æ¢
                        parent.children[i] = idx_scan
                    break
        else:
            # ORDER BYæ˜¯æ ¹èŠ‚ç‚¹
            if order_by_children:
                plan.root = order_by_children[0]
            else:
                plan.root = idx_scan
        
        self.decisions.append({
            'table': table_name,
            'column': order_column,
            'optimization': 'ORDER_BY_INDEX',
            'index_name': matching_index,
            'direction': order_direction,
            'chosen': True,
            'selectivity_estimate': 1.0  # ORDER BYç´¢å¼•ä¼˜åŒ–ä¸æ¶‰åŠé€‰æ‹©æ€§
        })
        
        return plan
    
    def _find_order_by_node(self, node):
        """æŸ¥æ‰¾ORDER BYç®—å­"""
        from .logical_operators import OrderByOperator
        if isinstance(node, OrderByOperator):
            return node
        
        if hasattr(node, 'children') and node.children:
            for child in node.children:
                result = self._find_order_by_node(child)
                if result:
                    return result
        return None
    
    def _find_scan_under_order_by(self, order_by_node):
        """æŸ¥æ‰¾ORDER BYä¸‹çš„SCANç®—å­"""
        from .logical_operators import ScanOperator
        
        def find_scan(node):
            if isinstance(node, ScanOperator):
                return node
            if hasattr(node, 'children') and node.children:
                for child in node.children:
                    result = find_scan(child)
                    if result:
                        return result
            return None
        
        return find_scan(order_by_node)
    
    def _replace_scan_with_index_scan(self, node, old_scan, new_index_scan):
        """åœ¨ç®—å­æ ‘ä¸­æŸ¥æ‰¾å¹¶æ›¿æ¢æŒ‡å®šçš„SCANèŠ‚ç‚¹ä¸ºIndexScan"""
        if hasattr(node, 'children') and node.children:
            for i, child in enumerate(node.children):
                if child is old_scan:
                    node.children[i] = new_index_scan
                else:
                    self._replace_scan_with_index_scan(child, old_scan, new_index_scan)
    
    def _replace_filter_scan_with_index_scan(self, node, plan):
        """
        ã€ä¿®å¤ç‰ˆã€‘é€’å½’æŸ¥æ‰¾å¹¶æ›¿æ¢ Filter(Scan) ä¸º IndexScanã€‚
        ä¿®å¤äº†å¯¹ASTæ¡ä»¶èŠ‚ç‚¹çš„è§£æé€»è¾‘ã€‚
        """
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        if hasattr(node, 'children') and node.children:
            # ä½¿ç”¨ list() åˆ›å»ºå‰¯æœ¬è¿›è¡Œè¿­ä»£ï¼Œå› ä¸ºæˆ‘ä»¬å¯èƒ½ä¼šä¿®æ”¹åˆ—è¡¨
            for child in list(node.children):
                self._replace_filter_scan_with_index_scan(child, plan)
        
        # æ£€æŸ¥å½“å‰èŠ‚ç‚¹æ˜¯å¦æ˜¯ Filter(Scan) æ¨¡å¼
        if isinstance(node, FilterOperator) and node.children:
            child = node.children[0]
            if isinstance(child, ScanOperator):
                table_name = child.table_name
                
                # --- ã€æ ¸å¿ƒä¿®å¤ã€‘ä½¿ç”¨æ–°çš„è§£æå‡½æ•° ---
                expr = getattr(node, 'condition', None)
                column_name, value, op = self.extract_eq_column_value(expr)
                
                # å¦‚æœæ²¡æœ‰è§£æå‡º "åˆ— = å€¼" çš„ç®€å•æ¡ä»¶ï¼Œåˆ™è·³è¿‡æ­¤ä¼˜åŒ–
                if not (column_name and value is not None and op in ('=', '==')):
                    return

                # --- æ ¸å¿ƒå†³ç­–é€»è¾‘ ---
                has_index = False
                index_name = None
                
                if self.catalog and self.catalog.has_index_on(table_name, column_name):
                    has_index = True
                    index_name = self.catalog.get_index_by_column(table_name, column_name)

                # å¦‚æœæœ‰ç´¢å¼•ï¼Œå°±ç›´æ¥æ›¿æ¢ï¼
                if has_index:
                    # åˆ›å»ºæ–°çš„ IndexScan é€»è¾‘ç®—å­
                    # æ³¨æ„ï¼š predicate_key å¿…é¡»æ˜¯å…ƒç»„
                    idx_scan = IndexScanOperator(
                        table_name=table_name,
                        index_name=index_name,
                        column_name=column_name,
                        predicate={'key': (value,)}
                    )

                    # åœ¨è®¡åˆ’æ ‘ä¸­æ›¿æ¢æ‰ Filter èŠ‚ç‚¹
                    parent = self._find_parent_of_node(plan.root, node)
                    if parent:
                        for i, child_node in enumerate(parent.children):
                            if child_node is node:
                                parent.children[i] = idx_scan
                                break
                    else: # Filter æ˜¯æ ¹èŠ‚ç‚¹
                        plan.root = idx_scan
                    
                    # è®°å½•å†³ç­–ï¼ˆç”¨äºè°ƒè¯•ï¼‰
                    self.decisions.append({
                        'table': table_name, 'column': column_name,
                        'predicate': str(expr), 'chosen': True, 'reason': 'ç´¢å¼•å­˜åœ¨',
                        'index_name': index_name
                    })

    def extract_eq_column_value(self, expr):
        """
        ã€äºŒæ¬¡ä¿®å¤ç‰ˆã€‘è§£æASTè¡¨è¾¾å¼ï¼Œæå–ç­‰å€¼æ¡ä»¶çš„åˆ—åå’Œå€¼ã€‚
        ä¸“é—¨ç”¨äºè§£æå½¢å¦‚ BinaryExpr(left=Identifier, operator=Token, right=Literal) çš„ASTèŠ‚ç‚¹ã€‚
        """
        # æ£€æŸ¥ expr æ˜¯å¦æ˜¯ BinaryExpr AST èŠ‚ç‚¹å¯¹è±¡
        # ã€å…³é”®ä¿®å¤ã€‘: å±æ€§åæ˜¯ operator, è€Œä¸æ˜¯ op
        if hasattr(expr, 'operator') and hasattr(expr, 'left') and hasattr(expr, 'right'):
            op_token = getattr(expr, 'operator', None)
            left_node = getattr(expr, 'left', None)
            right_node = getattr(expr, 'right', None)

            # æ£€æŸ¥æ“ä½œç¬¦Tokenæ˜¯å¦ä¸ºç­‰å·
            if not (hasattr(op_token, 'literal') and op_token.literal in ('=', '==')):
                return None, None, None

            # å‡è®¾å·¦è¾¹æ˜¯åˆ—å (Identifier), å³è¾¹æ˜¯å€¼ (Literal)
            # å®ƒä»¬éƒ½æœ‰ä¸€ä¸ª .value å±æ€§
            print(2)
            if hasattr(left_node, 'value') and hasattr(right_node, 'value'):
                print(3)
                column_name = left_node.value
                value = right_node.value
                op = op_token.literal
                
                # å…³é”®ï¼šå°†ä» Literal èŠ‚ç‚¹ä¸­å–å‡ºçš„å€¼ï¼ˆå®ƒå¯èƒ½æ˜¯å­—ç¬¦ä¸² '1'ï¼‰å°è¯•è½¬æ¢ä¸ºæ•°å­—
                try:
                    # å°è¯•è½¬ä¸ºæ•´æ•°ï¼Œå¦‚æœå¤±è´¥å†å°è¯•æµ®ç‚¹æ•°
                    if isinstance(value, str) and '.' in value:
                        value = float(value)
                    else:
                        value = int(value)
                except (ValueError, TypeError):
                    # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œä¿æŒåŸæ ·ï¼ˆä¾‹å¦‚å­—ç¬¦ä¸²ç±»å‹çš„å€¼ï¼‰
                    pass
                
                return column_name, value, op

        # å¦‚æœä¸åŒ¹é…ä¸Šé¢çš„ç»“æ„ï¼Œè¿”å›None
        return None, None, None

    def _is_equality_op(self, op: Optional[str]) -> bool:
        return op in ('=', '==')

    def _is_range_op(self, op: Optional[str]) -> bool:
        return op in ('<', '>', '<=', '>=')

    def _estimate_range_selectivity(self, table: str, column: str, cond_str: str) -> float:
        """æ”¹è¿›çš„é€‰æ‹©æ€§ä¼°ç®—ï¼š
        - ç­‰å€¼æŸ¥è¯¢ï¼šå‡è®¾10%é€‰æ‹©æ€§
        - èŒƒå›´æŸ¥è¯¢ï¼šå‡è®¾20%é€‰æ‹©æ€§
        - å…¶ä»–ï¼šå‡è®¾50%é€‰æ‹©æ€§
        """
        name = column.lower()
        if 'id' == name or 'time' in name:
            return 0.05  # 5%é€‰æ‹©æ€§
        elif '=' in cond_str or '==' in cond_str:
            return 0.1   # ç­‰å€¼æŸ¥è¯¢ï¼Œ10%é€‰æ‹©æ€§
        elif any(op in cond_str for op in ['<', '>', '<=', '>=']):
            return 0.2   # èŒƒå›´æŸ¥è¯¢ï¼Œ20%é€‰æ‹©æ€§
        else:
            return 0.5   # å…¶ä»–æƒ…å†µï¼Œ50%é€‰æ‹©æ€§

    def get_decisions(self) -> List[Dict[str, Any]]:
        return list(self.decisions)
    
    def _rule_push_predicates_down(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šè°“è¯ä¸‹æ¨"""
        # å°†è¿‡æ»¤æ¡ä»¶å°½å¯èƒ½é è¿‘æ•°æ®æº
        if plan.node_type == 'Join' and hasattr(plan.root, 'condition'):
            # å°†è¿æ¥æ¡ä»¶ä¸‹æ¨åˆ°å­èŠ‚ç‚¹
            if hasattr(plan.root, 'left_child') and plan.root.left_child:
                left_plan = LogicalPlan(plan.root.left_child)
                if left_plan.node_type == 'Scan':
                    if not hasattr(plan.root.left_child, 'condition'):
                        plan.root.left_child.condition = []
                    # æå–å·¦è¡¨ç›¸å…³çš„æ¡ä»¶
                    left_conditions = self._extract_table_conditions([plan.root.condition], plan.root.left_child.table_name)
                    if left_conditions:
                        plan.root.left_child.condition.extend(left_conditions)
            
            if hasattr(plan.root, 'right_child') and plan.root.right_child:
                right_plan = LogicalPlan(plan.root.right_child)
                if right_plan.node_type == 'Scan':
                    if not hasattr(plan.root.right_child, 'condition'):
                        plan.root.right_child.condition = []
                    # æå–å³è¡¨ç›¸å…³çš„æ¡ä»¶
                    right_conditions = self._extract_table_conditions([plan.root.condition], plan.root.right_child.table_name)
                    if right_conditions:
                        plan.root.right_child.condition.extend(right_conditions)
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        if hasattr(plan.root, 'left_child') and plan.root.left_child:
            left_plan = LogicalPlan(plan.root.left_child)
            plan.root.left_child = self._rule_push_predicates_down(left_plan).root
        if hasattr(plan.root, 'right_child') and plan.root.right_child:
            right_plan = LogicalPlan(plan.root.right_child)
            plan.root.right_child = self._rule_push_predicates_down(right_plan).root
        
        return plan
    
    def _extract_table_conditions(self, conditions: List, table_name: str) -> List:
        """æå–ç‰¹å®šè¡¨ç›¸å…³çš„æ¡ä»¶"""
        table_conditions = []
        for condition in conditions:
            if hasattr(condition, 'left') and hasattr(condition, 'right'):
                # æ£€æŸ¥æ¡ä»¶æ˜¯å¦åªæ¶‰åŠæŒ‡å®šè¡¨
                if (self._is_table_column(condition.left, table_name) and 
                    self._is_table_column(condition.right, table_name)):
                    table_conditions.append(condition)
        return table_conditions
    
    def _is_table_column(self, expr, table_name: str) -> bool:
        """æ£€æŸ¥è¡¨è¾¾å¼æ˜¯å¦åªæ¶‰åŠæŒ‡å®šè¡¨çš„åˆ—"""
        if hasattr(expr, 'table_name'):
            return expr.table_name == table_name
        return False
    
    def _rule_eliminate_redundant_operations(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šæ¶ˆé™¤å†—ä½™æ“ä½œ"""
        # æ¶ˆé™¤é‡å¤çš„æŠ•å½±
        if plan.node_type == 'Project' and hasattr(plan.root, 'children') and plan.root.children:
            left_child = plan.root.children[0]
            left_plan = LogicalPlan(left_child)
            if left_plan.node_type == 'Project':
                # åˆå¹¶ä¸¤ä¸ªæŠ•å½±æ“ä½œ
                if hasattr(plan.root, 'columns') and hasattr(left_child, 'columns'):
                    combined_columns = list(set(plan.root.columns + left_child.columns))
                    plan.root.columns = combined_columns
                    plan.root.children = left_child.children
        
        # æ¶ˆé™¤é‡å¤çš„è¿‡æ»¤
        if plan.node_type == 'Filter' and hasattr(plan.root, 'children') and plan.root.children:
            left_child = plan.root.children[0]
            left_plan = LogicalPlan(left_child)
            if left_plan.node_type == 'Filter':
                # åˆå¹¶ä¸¤ä¸ªè¿‡æ»¤æ¡ä»¶
                if hasattr(plan.root, 'condition') and hasattr(left_child, 'condition'):
                    # ç®€åŒ–å®ç°ï¼šä¿æŒåŸæ¡ä»¶
                    pass
        
        # é€’å½’å¤„ç†å­èŠ‚ç‚¹
        if hasattr(plan.root, 'children') and plan.root.children:
            for i, child in enumerate(plan.root.children):
                child_plan = LogicalPlan(child)
                plan.root.children[i] = self._rule_eliminate_redundant_operations(child_plan).root
        
        return plan
    
    def _rule_optimize_join_order(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šä¼˜åŒ–è¿æ¥é¡ºåº"""
        # åŸºäºæˆæœ¬é‡æ–°æ’åºè¿æ¥
        if plan.node_type == 'Join':
            # ç®€åŒ–å®ç°ï¼šæš‚æ—¶ä¸è¿›è¡Œè¿æ¥é¡ºåºä¼˜åŒ–
            pass
        
        return plan
    
    def _rule_constant_folding(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šå¸¸é‡æŠ˜å  - åœ¨ç¼–è¯‘æ—¶è®¡ç®—å¸¸é‡è¡¨è¾¾å¼"""
        # éå†è®¡åˆ’æ ‘ï¼ŒæŸ¥æ‰¾å¯ä»¥æŠ˜å çš„å¸¸é‡è¡¨è¾¾å¼
        self._fold_constants_in_operator(plan.root)
        return plan
    
    def _fold_constants_in_operator(self, operator):
        """åœ¨æ“ä½œç¬¦ä¸­æŠ˜å å¸¸é‡"""
        if hasattr(operator, 'condition'):
            operator.condition = self._fold_expression(operator.condition)
        
        # é€’å½’å¤„ç†å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                self._fold_constants_in_operator(child)
    
    def _fold_expression(self, expression):
        """æŠ˜å è¡¨è¾¾å¼ä¸­çš„å¸¸é‡"""
        if hasattr(expression, 'left') and hasattr(expression, 'right'):
            # äºŒå…ƒè¡¨è¾¾å¼
            left_folded = self._fold_expression(expression.left)
            right_folded = self._fold_expression(expression.right)
            
            # å¦‚æœå·¦å³éƒ½æ˜¯å­—é¢é‡ï¼Œå¯ä»¥æŠ˜å 
            if (hasattr(left_folded, 'value') and hasattr(right_folded, 'value') and
                hasattr(expression, 'operator')):
                try:
                    result = self._evaluate_binary_expression(
                        left_folded.value, expression.operator, right_folded.value
                    )
                    from .logical_operators import LiteralExpression
                    return LiteralExpression(result)
                except:
                    pass
            
            # åˆ›å»ºæ–°çš„è¡¨è¾¾å¼
            from .logical_operators import BinaryExpression
            new_expr = BinaryExpression(left_folded, expression.operator, right_folded)
            return new_expr
        
        return expression
    
    def _evaluate_binary_expression(self, left, operator, right):
        """è®¡ç®—äºŒå…ƒè¡¨è¾¾å¼"""
        if operator == '+':
            return left + right
        elif operator == '-':
            return left - right
        elif operator == '*':
            return left * right
        elif operator == '/':
            return left / right if right != 0 else 0
        elif operator == '=' or operator == '==':
            return left == right
        elif operator == '!=' or operator == '<>':
            return left != right
        elif operator == '<':
            return left < right
        elif operator == '>':
            return left > right
        elif operator == '<=':
            return left <= right
        elif operator == '>=':
            return left >= right
        else:
            raise ValueError(f"Unsupported operator: {operator}")
    
    def _rule_subquery_optimization(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šå­æŸ¥è¯¢ä¼˜åŒ– - å°†ç›¸å…³å­æŸ¥è¯¢è½¬æ¢ä¸ºè¿æ¥"""
        # æŸ¥æ‰¾å­æŸ¥è¯¢å¹¶å°è¯•è½¬æ¢ä¸ºè¿æ¥
        self._optimize_subqueries_in_operator(plan.root)
        return plan
    
    def _optimize_subqueries_in_operator(self, operator):
        """åœ¨æ“ä½œç¬¦ä¸­ä¼˜åŒ–å­æŸ¥è¯¢"""
        if hasattr(operator, 'condition'):
            operator.condition = self._optimize_subquery_in_expression(operator.condition)
        
        # é€’å½’å¤„ç†å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                self._optimize_subqueries_in_operator(child)
    
    def _optimize_subquery_in_expression(self, expression):
        """åœ¨è¡¨è¾¾å¼ä¸­ä¼˜åŒ–å­æŸ¥è¯¢"""
        # è¿™é‡Œå¯ä»¥å®ç°å°†EXISTSå­æŸ¥è¯¢è½¬æ¢ä¸ºåŠè¿æ¥ç­‰ä¼˜åŒ–
        # ç”±äºå½“å‰ç³»ç»Ÿç»“æ„é™åˆ¶ï¼Œè¿™é‡Œå…ˆè¿”å›åŸè¡¨è¾¾å¼
        return expression
    
    def _rule_predicate_simplification(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šè°“è¯ç®€åŒ– - ç®€åŒ–å¤æ‚çš„è°“è¯æ¡ä»¶"""
        self._simplify_predicates_in_operator(plan.root)
        return plan
    
    def _simplify_predicates_in_operator(self, operator):
        """åœ¨æ“ä½œç¬¦ä¸­ç®€åŒ–è°“è¯"""
        if hasattr(operator, 'condition'):
            operator.condition = self._simplify_expression(operator.condition)
        
        # é€’å½’å¤„ç†å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                self._simplify_predicates_in_operator(child)
    
    def _simplify_expression(self, expression):
        """ç®€åŒ–è¡¨è¾¾å¼"""
        if hasattr(expression, 'left') and hasattr(expression, 'right'):
            # ç®€åŒ–äºŒå…ƒè¡¨è¾¾å¼
            left_simplified = self._simplify_expression(expression.left)
            right_simplified = self._simplify_expression(expression.right)
            
            # å¤„ç†ä¸€äº›å¸¸è§çš„ç®€åŒ–è§„åˆ™
            if (hasattr(expression, 'operator') and 
                hasattr(left_simplified, 'value') and 
                hasattr(right_simplified, 'value')):
                
                # å¤„ç†æ’çœŸ/æ’å‡æ¡ä»¶
                if expression.operator in ['=', '=='] and left_simplified.value == right_simplified.value:
                    from .logical_operators import LiteralExpression
                    return LiteralExpression(True)
                elif expression.operator in ['!=', '<>'] and left_simplified.value == right_simplified.value:
                    from .logical_operators import LiteralExpression
                    return LiteralExpression(False)
            
            from .logical_operators import BinaryExpression
            return BinaryExpression(left_simplified, expression.operator, right_simplified)
        
        return expression
    
    def _rule_column_elimination(self, plan: LogicalPlan) -> LogicalPlan:
        """è§„åˆ™ï¼šåˆ—æ¶ˆé™¤ - æ¶ˆé™¤ä¸éœ€è¦çš„åˆ—"""
        # åˆ†ææŸ¥è¯¢ä¸­å®é™…ä½¿ç”¨çš„åˆ—ï¼Œæ¶ˆé™¤æœªä½¿ç”¨çš„åˆ—
        self._eliminate_unused_columns_in_operator(plan.root)
        return plan
    
    def _eliminate_unused_columns_in_operator(self, operator):
        """åœ¨æ“ä½œç¬¦ä¸­æ¶ˆé™¤æœªä½¿ç”¨çš„åˆ—"""
        if hasattr(operator, 'columns'):
            # è¿™é‡Œå¯ä»¥å®ç°åˆ—ä½¿ç”¨åˆ†æï¼Œæ¶ˆé™¤æœªå¼•ç”¨çš„åˆ—
            # ç”±äºéœ€è¦å¤æ‚çš„ä¾èµ–åˆ†æï¼Œè¿™é‡Œå…ˆä¿æŒåŸæ ·
            pass
        
        # é€’å½’å¤„ç†å­æ“ä½œç¬¦
        if hasattr(operator, 'children') and operator.children:
            for child in operator.children:
                self._eliminate_unused_columns_in_operator(child)
    
    def _estimate_join_cardinality(self, left_card: int, right_card: int, join_type: str) -> int:
        """ä¼°ç®—è¿æ¥åŸºæ•°"""
        if join_type == 'inner':
            # å†…è¿æ¥ï¼šå‡è®¾é€‰æ‹©æ€§ä¸º0.1
            return int(left_card * right_card * 0.1)
        elif join_type == 'left':
            # å·¦å¤–è¿æ¥ï¼šè‡³å°‘ç­‰äºå·¦è¡¨åŸºæ•°
            return max(left_card, int(left_card * right_card * 0.1))
        elif join_type == 'right':
            # å³å¤–è¿æ¥ï¼šè‡³å°‘ç­‰äºå³è¡¨åŸºæ•°
            return max(right_card, int(left_card * right_card * 0.1))
        else:
            # é»˜è®¤æƒ…å†µ
            return int(left_card * right_card * 0.1)

class OptimizationAnalyzer:
    """ä¼˜åŒ–åˆ†æå™¨"""
    
    def __init__(self, optimizer: QueryOptimizer):
        self.optimizer = optimizer
    
    def analyze_query(self, sql: str) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢å¹¶æä¾›ä¼˜åŒ–å»ºè®®"""
        # 1. è§£ææŸ¥è¯¢
        from .lexicalAnalysis import tokenize
        from .new_syntax_analyzer import NewSyntaxAnalyzer as SyntaxAnalyzer
        from .enhanced_semantic_analyzer import EnhancedSemanticAnalyzer as SemanticAnalyzer
        
        tokens = tokenize(sql)
        syntax_analyzer = SyntaxAnalyzer()
        ast = syntax_analyzer.build_ast_from_tokens(tokens)
        
        semantic_analyzer = SemanticAnalyzer(self.optimizer.symbol_table)
        if not semantic_analyzer.analyze(ast):
            return {"error": "è¯­ä¹‰åˆ†æå¤±è´¥"}
        
        # 2. ç”Ÿæˆæ‰§è¡Œè®¡åˆ’
        planner = EnhancedQueryPlanner(self.optimizer.symbol_table)
        logical_plan = planner.create_plan(ast)
        
        # 3. ä¼˜åŒ–è®¡åˆ’
        optimized_plan = self.optimizer.optimize(logical_plan)
        
        # 4. åˆ†æç»“æœ
        analysis = {
            "original_plan": self._plan_to_dict(logical_plan),
            "optimized_plan": self._plan_to_dict(optimized_plan),
            "optimization_suggestions": self._generate_suggestions(sql, logical_plan, optimized_plan),
            "performance_metrics": self._calculate_metrics(logical_plan, optimized_plan),
            "index_decisions": self._format_index_decisions()
        }
        
        return analysis

    def _plan_to_dict(self, plan: LogicalPlan) -> Dict[str, Any]:
        """å°†æ‰§è¡Œè®¡åˆ’è½¬æ¢ä¸ºå­—å…¸ï¼ˆç”¨äºæŠ¥å‘Šå±•ç¤ºï¼‰"""
        return {
            "root_operator": type(plan.root).__name__,
            "cost": self.optimizer.cost_model.calculate_cost(plan, self.optimizer.statistics).total_cost
        }

    def _generate_suggestions(self, sql: str, original_plan: LogicalPlan, optimized_plan: LogicalPlan) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions: List[str] = []
        if "WHERE" in sql.upper() and not self._has_index_usage(original_plan):
            suggestions.append("è€ƒè™‘ä¸ºWHEREæ¡ä»¶ä¸­çš„åˆ—åˆ›å»ºç´¢å¼•")
        if "SELECT *" in sql.upper():
            suggestions.append("é¿å…ä½¿ç”¨SELECT *ï¼Œåªé€‰æ‹©éœ€è¦çš„åˆ—")
        if "JOIN" in sql.upper():
            suggestions.append("æ£€æŸ¥è¡¨è¿æ¥é¡ºåºï¼Œå°†å°è¡¨æ”¾åœ¨å‰é¢")
        return suggestions

    def _has_index_usage(self, plan: LogicalPlan) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•ï¼ˆç®€åŒ–å®ç°ï¼Œå ä½ï¼‰"""
        return False

    def _calculate_metrics(self, original_plan: LogicalPlan, optimized_plan: LogicalPlan) -> Dict[str, Any]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        original_cost = self.optimizer.cost_model.calculate_cost(original_plan, self.optimizer.statistics)
        optimized_cost = self.optimizer.cost_model.calculate_cost(optimized_plan, self.optimizer.statistics)
        improvement = ((original_cost.total_cost - optimized_cost.total_cost) / original_cost.total_cost) * 100 if original_cost.total_cost > 0 else 0.0
        io_reduction = ((original_cost.io_cost - optimized_cost.io_cost) / original_cost.io_cost) * 100 if original_cost.io_cost > 0 else 0.0
        cpu_reduction = ((original_cost.cpu_cost - optimized_cost.cpu_cost) / original_cost.cpu_cost) * 100 if original_cost.cpu_cost > 0 else 0.0
        return {
            "original_cost": original_cost.total_cost,
            "optimized_cost": optimized_cost.total_cost,
            "improvement_percentage": improvement,
            "io_reduction": io_reduction,
            "cpu_reduction": cpu_reduction
        }

    def _format_index_decisions(self) -> List[Dict[str, Any]]:
        """è¿”å›ç´¢å¼•é€‰æ‹©å¯è§†åŒ–æ•°æ®"""
        decisions = []
        if hasattr(self.optimizer.rule_engine, 'get_decisions'):
            for d in self.optimizer.rule_engine.get_decisions():
                # ç”Ÿæˆç®€æ´æ¡ç›®
                decisions.append({
                    'table': d.get('table'),
                    'column': d.get('column'),
                    'predicate': d.get('predicate'),
                    'operator': d.get('operator'),
                    'selectivity': round(float(d.get('selectivity_estimate', 0.0)), 4),
                    'seq_cost': round(float(d.get('seq_cost_estimate', 0.0)), 4),
                    'index_cost': round(float(d.get('index_cost_estimate', 0.0)), 4),
                    'chosen': d.get('chosen'),
                    'index_name': d.get('index_name')
                })
        return decisions


class CardinalityEstimator:
    """åŸºæ•°/é€‰æ‹©æ€§ä¼°ç®—å™¨ï¼šä½¿ç”¨ CatalogManager ä¸­çš„åˆ—ç»Ÿè®¡"""
    def __init__(self, catalog: CatalogManager | None):
        self.catalog = catalog

    def estimate_selectivity(self, table: str, column: str, op: Optional[str], cond_str: str) -> Optional[float]:
        if self.catalog is None:
            return None
        try:
            cs = self.catalog.get_column_stats(table, column)
            t = self.catalog.get_table(table)
        except Exception:
            return None
        if cs is None:
            return None
        row_count = max(1, getattr(t, 'row_count', 0))
        distinct = max(1, int(cs.get('distinct') or 1))
        # å°è¯•è§£æå³å€¼
        rhs_value = self._parse_rhs_value(cond_str)
        # ç­‰å€¼ï¼šä¼˜å…ˆç”¨ MCV
        if op in ('=', '=='):
            mcv = cs.get('mcv') or []  # [(value, freq)]
            if rhs_value is not None and mcv:
                total = max(1, getattr(t, 'row_count', 1))
                for val, freq in mcv:
                    if str(val) == str(rhs_value):
                        return min(1.0, float(freq) / float(total))
            return min(1.0, 1.0 / distinct)
        if op in ('<', '<=', '>', '>='):
            # å…ˆå°è¯•ç›´æ–¹å›¾
            hist = cs.get('histogram') or []  # [(bucket_high, freq)] ç´¯è®¡æˆ–å•æ¡¶é¢‘æ¬¡
            total_rows = max(1, getattr(t, 'row_count', 1))
            if rhs_value is not None and hist:
                try:
                    # è§†ä¸ºæŒ‰ bucket_high å‡åº
                    buckets = sorted(hist, key=lambda x: float(x[0]))
                    cum = 0.0
                    if op in ('<', '<='):
                        for bh, freq in buckets:
                            if float(rhs_value) >= float(bh):
                                cum += float(freq)
                            else:
                                break
                        return max(0.0, min(1.0, cum / float(total_rows)))
                    else:
                        # > or >=
                        for bh, freq in buckets:
                            if float(rhs_value) < float(bh):
                                # è¿˜æœªè¦†ç›–åˆ° rhs_value çš„æ¡¶éƒ½è®¡å…¥å³ä¾§å‰©ä½™
                                pass
                        # ç®€åŒ–ï¼š1 - P(x <= v)
                        left = 0.0
                        for bh, freq in buckets:
                            if float(rhs_value) >= float(bh):
                                left += float(freq)
                            else:
                                break
                        return max(0.0, min(1.0, (float(total_rows) - left) / float(total_rows)))
                except Exception:
                    pass
            # å›é€€ç”¨ min/max çº¿æ€§ä¼°è®¡
            cmin = cs.get('min')
            cmax = cs.get('max')
            v = None
            if isinstance(rhs_value, (int, float)):
                v = float(rhs_value)
            if v is not None and isinstance(cmin, (int, float)) and isinstance(cmax, (int, float)) and cmax > cmin:
                if op in ('<', '<='):
                    frac = max(0.0, min(1.0, (v - cmin) / (cmax - cmin)))
                else:
                    frac = max(0.0, min(1.0, (cmax - v) / (cmax - cmin)))
                return frac
            return 0.1
        return None

    def _parse_rhs_value(self, cond_str: str) -> Optional[Any]:
        """ä»å½¢å¦‚"(col OP value)"çš„å­—ç¬¦ä¸²ä¸­è§£æå³å€¼ã€‚"""
        try:
            tokens = cond_str.strip().strip('()').split()
            if len(tokens) < 3:
                return None
            raw = tokens[2]
            s = raw.strip()
            if (s.startswith("'") and s.endswith("'")) or (s.startswith('"') and s.endswith('"')):
                return s[1:-1]
            # æ•°å­—
            if '.' in s:
                return float(s)
            return int(s)
        except Exception:
            return None
    
    def _plan_to_dict(self, plan: LogicalPlan) -> Dict[str, Any]:
        """å°†æ‰§è¡Œè®¡åˆ’è½¬æ¢ä¸ºå­—å…¸"""
        return {
            "root_operator": type(plan.root).__name__,
            "cost": self.optimizer.cost_model.calculate_cost(plan, self.optimizer.statistics).total_cost
        }
    
    def _generate_suggestions(self, sql: str, original_plan: LogicalPlan, optimized_plan: LogicalPlan) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•
        if "WHERE" in sql.upper() and not self._has_index_usage(original_plan):
            suggestions.append("è€ƒè™‘ä¸ºWHEREæ¡ä»¶ä¸­çš„åˆ—åˆ›å»ºç´¢å¼•")
        
        # æ£€æŸ¥SELECT *
        if "SELECT *" in sql.upper():
            suggestions.append("é¿å…ä½¿ç”¨SELECT *ï¼Œåªé€‰æ‹©éœ€è¦çš„åˆ—")
        
        # æ£€æŸ¥è¿æ¥é¡ºåº
        if "JOIN" in sql.upper():
            suggestions.append("æ£€æŸ¥è¡¨è¿æ¥é¡ºåºï¼Œå°†å°è¡¨æ”¾åœ¨å‰é¢")
        
        return suggestions
    
    def _has_index_usage(self, plan: LogicalPlan) -> bool:
        """æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†ç´¢å¼•"""
        # ç®€åŒ–å®ç°
        return False
    
    def _calculate_metrics(self, original_plan: LogicalPlan, optimized_plan: LogicalPlan) -> Dict[str, Any]:
        """è®¡ç®—æ€§èƒ½æŒ‡æ ‡"""
        original_cost = self.optimizer.cost_model.calculate_cost(original_plan, self.optimizer.statistics)
        optimized_cost = self.optimizer.cost_model.calculate_cost(optimized_plan, self.optimizer.statistics)
        
        # é¿å…é™¤é›¶é”™è¯¯
        if original_cost.total_cost > 0:
            improvement = ((original_cost.total_cost - optimized_cost.total_cost) / original_cost.total_cost) * 100
        else:
            improvement = 0.0
        
        # è®¡ç®—I/Oå‡å°‘ç™¾åˆ†æ¯”
        if original_cost.io_cost > 0:
            io_reduction = ((original_cost.io_cost - optimized_cost.io_cost) / original_cost.io_cost) * 100
        else:
            io_reduction = 0.0
        
        # è®¡ç®—CPUå‡å°‘ç™¾åˆ†æ¯”
        if original_cost.cpu_cost > 0:
            cpu_reduction = ((original_cost.cpu_cost - optimized_cost.cpu_cost) / original_cost.cpu_cost) * 100
        else:
            cpu_reduction = 0.0
        
        return {
            "original_cost": original_cost.total_cost,
            "optimized_cost": optimized_cost.total_cost,
            "improvement_percentage": improvement,
            "io_reduction": io_reduction,
            "cpu_reduction": cpu_reduction
        }

def create_optimizer(symbol_table: SymbolTable, strategy: OptimizationStrategy = OptimizationStrategy.HYBRID, catalog_manager: CatalogManager | None = None, enable_optimization: bool = True) -> QueryOptimizer:
    """åˆ›å»ºæŸ¥è¯¢ä¼˜åŒ–å™¨å®ä¾‹ï¼Œå…è®¸æ³¨å…¥ CatalogManager"""
    return QueryOptimizer(symbol_table, strategy, catalog_manager, enable_optimization)

def optimize_query(sql: str, symbol_table: SymbolTable, catalog_manager: CatalogManager | None = None) -> Dict[str, Any]:
    """ä¼˜åŒ–æŸ¥è¯¢çš„ä¾¿æ·å‡½æ•°ï¼Œå…è®¸æ³¨å…¥ CatalogManager"""
    optimizer = create_optimizer(symbol_table, catalog_manager=catalog_manager)
    analyzer = OptimizationAnalyzer(optimizer)
    return analyzer.analyze_query(sql)
